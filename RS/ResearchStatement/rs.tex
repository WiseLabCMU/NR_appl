\documentclass[10pt]{article}

%\usepackage{fancyhdr}
 
%\pagestyle{headings}
%\markright{John Smith}

\date{}

\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage[colorlinks=true,citecolor=blue]{hyperref}   % use for hypertext links
\usepackage{lipsum}
\usepackage{url}

\usepackage[margin=1in]{geometry}

\usepackage{graphicx}
\usepackage{balance}
\usepackage{comment}
\usepackage{amssymb,amsmath}
\usepackage{caption}
\DeclareCaptionType{copyrightbox}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage{color}
\usepackage{titling}
%\usepackage{subcaption}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tableref}[1]{Table~\ref{tab:#1}}

\newcommand{\compactimg}{\vspace{-12pt}}

\clubpenalty=10000 
\widowpenalty=10000
\setlength{\parindent}{0cm}



\begin{document}
\pagenumbering{gobble}

\begin{table}
\color{blue}
%\color{Emerald}
\begin{tabular*}{\textwidth}{l r}
\large\textbf{RESEARCH STATEMENT} & 
\hfill \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\large\textbf{NIRANJINI RAJAGOPAL}\\
\hline
\end{tabular*}

\end{table}

We live in exciting times where new applications of cyber-physical systems
(CPS) are emerging to improve efficiency and safety. Examples include smart buildings, industrial internet of things, smart manufacturing, mixed reality, autonomous vehicles, and healthcare technology. These systems have embedded platforms with sensors and actuators connected over a network and integrated with real-time computation. Central to these systems, and the focus of my work is - making an inference about the physical world. I design the sensing and inference pipeline end-end by joint design of sensor front-end, system models, the networked embedded system and the information processing algorithms. 



Classical system design is split into components that are designed independently : (1) the embedded platform that can produce and sense signals (2) the distributed network (3) the information processing algorithms. This works when we have well defined models and interfaces for the interaction of real world with signals. However, emerging CPS have distributed heterogeneous components and have to make inferences that go beyond simple sensors and systems. As a result, on one hand we have siloed system implementations that use custom sensors and devices and work in some environments but don't generalize and cannot be systematically analyzed. On the other hand we have tools for information processing and analysis that is far removed from practice. To face the challenges of modern CPS, I build reliable networked embedded sensing systems by (1) designing novel sensing methods that are practical and generalize to the sensor type; this gives us more information with available sensors. (2) designing new system models that are simple; they can be systematically analyzed and help us design tools for achieving high performance with low resources; they work in practice (3) designing information processing algorithms; I draw tools from signal processing, estimation, optimization based on the problem at hand. My methodology is to work close to the physical layer, understand signals and systems from first principles. I experiment and deploy systems in the real-world. \\

\textbf{Old intro:}\\
We live in exciting times where we are finally seeing cyber-physical systems (CPS) applications being applied to improve efficiency and safety. Examples include interactive experiences with mixed reality, smart and responsive buildings, autonomous vehicles, smart manufacturing, industrial internet of things, and computing to improve healthcare. These systems are large in scale, operate in unpredictable environments and literally have many moving parts.  This disrupts classical siloed system design, where systems are broken down into components from different domains, each with their own tools and design methodology. For instance, system implementations and algorithms are often tuned to the environment or technology. 
This makes it hard to analyze the system for properties such as reliability and
robustness. On the other hand, if we remove properties of the real
world and abstract systems to well-understood models, we can
systematically analyze them and predict their functionality. But this
analysis is far removed from practical systems. To face the challenges of modern CPS, 
%I solves the challenges that arise when we integrate 
%my approach is to identify and solve the challenges that arise across these layers.
I bring to embedded sensing systems research, a systematic understanding of signal processing, system modeling, inference, state estimation and communication. %I identify and solves challenges that arise across these layers  key to building reliable systems that work in the real world. %on challenges that arise when we Sp
I apply information processing tools from signal processing, estimation, optimization to embedded sensing systems to build reliable systems for the real-world.\\
%To build truly reliable and scalable systems that work in the real
%world I adopt an end-end approach spanning
%practical system design and theoretical system analysis.\\


Rather than the traditional siloed approach, I jointly design the sensing pipeline, system models and information processing algorithms and physical networked embedded system. Common to my methodology is (a) I work closely to the physical layer (b) I experiment and deploy systems in the real-world to understand the interaction between signals and systems from first principles (c) I develop signal, sensor and system models (d) I identify and implement the theoretical tools relevant to the estimation problem (e) I jointly determine the design parameters of the networked embedded system (sensor front-end modifications, what
infrastructure to use? where to place them? what sensors to collect
data from? how to schedule the devices? how to synchronize them? what communication scheme?) and design and implement the
information processing algorithms.\\

For instance, in the area of indoor localization, my first approach was to jointly design algorithms for beacon placement and location estimation. This joint design reduces the number of beacons, and makes the estimation robust. %Another example of my approach, is that I designed a novel sensing method using magnetic field for orientation acquisition. I used this to design algorithms for generating maps of magnetic field with pedestrians walking around, and an algorithm for instant orientation acquisition. % estimation algorithm and mapping algorithms and an end-end approach for automatically generating magnetic maps and instantly acquiring orientation of the phone. 
Another example is in the design of a visible light communication system. I designed a modulation scheme for LED lights and a demodulation scheme for cameras that leveraged the properties of the communication channel and the properties of sensors, and use this communication scheme to design the firmware on the LEDs and the phone.



\paragraph{Impact:}  In 2013, when LED lights were phasing out
incandescent lights, I designed one of the earliest visible light
communication (VLC) systems to send data from overhead LED lights and
for light-based localization. This work was published in IPSN'14\cite{rajagopal2014visual}
(cited 130+ times), VLCS'14 \cite{rajagopal2014hybrid} and demonstrated in IPSN'14 \cite{rajagopal2014demonstration}.  My
dissertation contributed to beacon-based indoor localization systems
for mobile devices, and resulted in several publications (SenSys'15 \cite{lazik2015alps},
RTAS'15 \cite{rtas-alps-platform}, IPIN'16 \cite{rajagopal2016beacon}, IPSN'18 \cite{rajagopal2018enhancing}, two under submission \cite{mobileAR, beaconplacementtheory}, demonstrations at
Sensys'15 \cite{lazik2015alpsdemo}, IPSN'18 \cite{rajagopal2018welcome}), received 2 patents, won the international
Microsoft Indoor Localization competition twice, received a best demo
award, spawned a startup, and has led to funding from NSF, SRC, NIST, and
industry. This work is being applied to indoor navigation, mobile
persistent augmented reality, firefighter localization, and asset
mapping applications.  I have also contributed to other areas of CPS:
time-synchronization (RTSS'14 \cite{buevich2013hardware}, RTAS'17 \cite{dongare2017pulsar}) and electrical energy
monitoring (ICCSP'13 \cite{rajagopal2013magnetic}, demonstrated at ICCPS'13 \cite{rajagopal2013demo}).

\section{Current Research}

My dissertation is on indoor localization - an instance of a CPS problem. Location gives information on where resources, things, people and devices are, and is an important service for other CPS applications

There are more than a million papers on indoor localization. Yet we get lost indoors today. The reason is --- we don't have solutions that are free-of-cost, do not require any environment-specific calibration, are accurate, robust and instant (do not require the user to walk around some distance). Existing solutions that use signals from WiFi, and on-board sensors such as camera and inertial sensors are free but depending on the implementation they have trade offs between accuracy, time-to-first-estimate and require environment-specific calibration. Solutions that deploy infrastructure can be accurate and instant if sufficient infrastructure (beacons or anchors) are in line-of-sight. A device localizes itself with respect to beacons by using a range-based measurement technique (time-of-flight, time-difference-of-arrival, angle-of-arrival). However, this system is not free since we have to install beacons densely across buildings, and setup and map them. \\


%jointly designed a method for both mapping beacons, as well as generating maps that enable instant orientation acquisition subsequently when  which   algorithm for  the system an information processing algorithms is 

\textbf{Platform and ranging technologies:} I argue that in the future, ranging capability will be available on commodity devices, WiFi access points, IoT devices and possibly smart appliances. %all devices that require localization service. 
Time-of-Flight (ToF) ranging is emerging through various wireless standards. % and is getting integrated into commodity devices, WiFi access points, and IoT devices. I believe that in future,  
The emerging technologies include mmWave, ultra-wideband (including emerging 802.18.4z), WiF 802.11mc and BLE5. On the platform side I contributed to building an ultrasonic platform that localizes unmodified mobile devices. The ultrasonic beacons harvest energy from overhead lights, are synchronized using 802.15.4 and use BLE advertisement packets to synchronize mobile devices
\cite{rtas-alps-platform, lazik2015alps,lazik2015alpsdemo}. I worked with Apple's earliest versions of WiFi ToF, during an internship, and subsequently this had product impact. I am also collaborating with Texas Instruments on BLE5 ToF ranging. 

My strategy to solve the indoor localization problem is to adopt time-of-flight ranging paradigm and built the tools required to make ToF localization accurate and instant with low beacon density; and create tools for automatic beacon placement and mapping. 

\paragraph{A robust location-solving algorithm: }
ToF systems require high density beacon coverage and suffer when they receive incorrect measurements due to
non-line-of-sight (NLOS) signals. 
% that reflect off surfaces where there isn't a direct path between the beacon and the device being localized. 
In realistic conditions, the user has walk around for the system to gather more measurements and converge. After facing this problem in several real-world deployments, I wanted to create a robust solver that localized instantly and accurately, with minimal LOS measurements and was robust to NLOS measurements. 

I solved this problem with a new idea that is simple and effective in practice \cite{rajagopal2018enhancing}. 
I compute the LOS coverage region for each beacon by using the floor plan geometry and a ray tracing model for beacon coverage. Rather than using low-level signal statistics or temporal information (both defeat the purpose of the instant solver), or assume knowledge of NLOS signal path (infeasible in practice), I assume that the NLOS signal travels a longer path than the LOS signal (which is true for all ranging technologies). The key innovation in the solver is that I also use the absence of measurement from certain beacons as useful information. I designed a hypothesis-testing floor-plan aware solver that checks for consistency between the received and absent measurements and the beacon coverage model.

This solver is the first that localizes with just two LOS beacons, rather than three (for 2D localization), and maintains the same performance even when several NLOS signals are present. Across several real
world environments, this solver detected and removed NLOS with 91\% accuracy and maintained 1m accuracy as compared to 4-8m by traditional approaches. We implemented this
method in our system that won the Microsoft Indoor
Localization Competition in 2015. 

\paragraph{Beacon placement algorithms: }
Anyone who has deployed a localization system at building-scale with a limited budget for beacons faces the challenge of not knowing where to place them. % and how to optimize the placement. 
Hence, more beacons than necessary are deployed and some amount of domain expertise is required for placing beacons. 

%The localization performance depends on where we placed the beacons. So 
I designed beacon placement algorithms in a
MATLAB-based toolchain available on GitHub, where users can draw or provide real world floor plans. They can
then try out different beacon placements and compare them quantitatively \cite{rajagopal2016beacon}. 

I used the insights from the floor-plan aware solver to design the placement algorithms. 
I define a location to be uniquely localizable if the location is covered by three or more beacons, or if it is covered by two beacons and the other location with the exact same distances from the two beacons has a different beacon set coverage. I designed a greedy beacon placement algorithm that optimizes for area that is uniquely localizable.  The algorithm reduced the number of beacons by $33\%$ compared to minimal placement with 3-beacon coverage across real-world and simulated floor plans. 
To account for accuracy in addition to coverage, I adopted the Cramer-Rao lower bound on the location estimate. This depends on the geometric dilution-of-precision (GDOP) - an analytical function of the angles between the beacons and the location; and standard deviation assuming additive Gaussian noise model for ranging error. I use the GDOP and the unique localization function over all regions to generate an expected CDF from any deployment, and design a second greedy beacon placement algorithm that optimizes for expected accuracy.  

I extended this work in collaboration with
Prof. Jie Gao from Stony Brook and her student. We mathematically
formulated the beacon placement problem for unique localization and proposed placement
algorithms with provable guarantees \cite{beaconplacementtheory}. Such systematic approaches and automated tools for beacon
placement are necessary while scaling up these systems from labs to
building-scale. 

Through these two works, my approach was to understand the interaction between ranging signals and real-world environments from first principles, design models of signals (LOS, NLOS), and systems (floor plan, beacon coverage) that were close to practical and general enough to systematically analyze. I used these principles to design the deployment of the system. 


% \paragraph{Tracking and mapping algorithms}
% I fused beacon ranges with visual-inertial odometry on phones with a Particle Filter approach. This implementation won the Microsoft Indoor Localization competition in 2018 with ultra-wideband beacons. The next problem we solved was automatic beacon mapping. In future, when WiFi access points, IoT devices and mobile devices have ranging capabilities, devices that are stationary can begin to act as beacons, and have to be mapped in real-time. Beacon mapping is also applicable for applications like asset mapping. I implemented a Rao Blackwellized-based Range-only Simultaneous Localization and Mapping algorithm to perform automatic beacon mapping by a pedestrian simply walking around holding a phone. 

\paragraph{Orientation acquisition, tracking and mapping algorithms}


To support continuous location updates, I fused beacon ranges with visual-inertial odometry on phones with a Particle Filter approach. This implementation won the Microsoft Indoor Localization competition in 2018 with ultra-wideband beacons. The next problem we solved was automatic beacon mapping. In future, when WiFi access points, IoT devices and mobile devices have ranging capabilities, devices that are stationary can begin to act as beacons, and have to be mapped in real-time. Beacon mapping is also applicable for applications like asset mapping. I implemented a Rao Blackwellized-based Range-only Simultaneous Localization and Mapping algorithm to perform automatic beacon mapping by a pedestrian simply walking around holding a phone. 

While most indoor localization work focuses on location
estimation, orientation is necessary for applications like mobile
augmented reality. %Existing approaches either rely on visual features
%or require the user to walk around for some distance before the
%orientation can be acquired.
I designed a novel approach where we fused Visual
Inertial Odometry and beacons to crowd-source a dense magnetic field
map with pedestrian-held phones. Subsequently, future users use this map at startup to calibrate
their compass in order to instantly estimate orientation. %Though
%magnetic field has been shown to be promising for localization, 
This is the first phone-based system that shows the feasibility of using magnetic field for
for instant orientation acquisition. %We also automatically map the beacon
%infrastructure as the pedestrian walks around with a phone.  
We used
this system to build and end-end multi-user persistent augmented
reality system that works in any environment without requiring the
sharing of large and often fragile point-cloud maps \cite{mobileAR}. 

This work won best demo award at IPSN 2018 \cite{rajagopal2018welcome}. The approach of mobile AR using beacons is implemented on our ultrasonic localization system that spawned into a startup. It has been deployed for AR-based product finding in retail. 

%In these two works, I analyzed the magnetic field spatial and temporal variation at the physical layer, created models and designed algorithms for location acquisition, tracking and mapping algorithms, and used these to build an end-end mobile AR application. 



%\subsection{Other CPS areas}
\paragraph{Localizing using the lighting infrastructure}
Though not the focus of my dissertation, my first approach to indoor localization to leverage existing infrastructure, was to localize using the overhead LED lights. To make this happen, I built an end-end visible light communication system.  LED lights turn on and off at a high frequency, offering an opportunity to use them as a communication channel to send data to mobile devices. The main challenge is that the lights operate at a much higher frequency than the camera frame rate.%But the lights
To communicate data despite this limitation, I designed a novel sensing approach to exploit the low-level rolling-shutter effect of camera sensors on phones to capture a time-varying light signal as a spatially varying image \cite{rajagopal2014visual, rajagopal2014demonstration}. %detect a high frequency light signal and used this to
I designed a modulation scheme that supported multiple lights.  
%A
%practical challenge was in maintaining performance when the user holds
%the phone normally, rather than pointing at the light. To overcome
%this, 
To make the system robust to real-world applications, I modeled the exposure and focus control of the camera as
filters that respond differently to the light signal and the scene
captured to improve the signal-to-noise ratio. %This
%was one of the earliest systems for LED camera communication using the rolling shutter effect
We extended the work
\cite{rajagopal2014hybrid} to design a hybrid communication scheme
where a single light transmits two independent data streams at
different data rates simultaneously to a phone and a photo-diode. I
presented this in the first Visible Light Communication
(VLC) workshop. %I learnt there that lights driving localization was a 

Subsequently, the field of
VLC has grown significantly with several rolling-shutter based
approaches for communication and localization, in both academia and
start-ups. Our work was one of the earliest works in LED-camera communication and using VLC for
localization. 


\paragraph{Effect of use case on system design} 
%There is no silver bullet for a localization architecture. % localization architecture 
We are working with National Institute of Standards and Technologies (NIST) on the challenging problem of localizing firefighters during an operation. Here, the challenge is that we cannot rely on any existing beacons inside the building. Our solution has a combination of fixed beacons on firetrucks; firefighters with wearable devices; and estimation algorithms based on mobile network localization. We are exploring the possibility of the exit signs on buildings becoming potential locations for low-power beacons that operate in emergencies. The system design has to adapt to the use case. In future, I would integrate a network of drones with this architecture to make the communication and localization more resilient.%It is likely that in future we would have different grades of reliabiity in localization technologies, some for emergency\\

I recently participated in a conference on mobile positioning for museums. My goal was to deep dive into one use-case segment in depth. I learnt that the concerns were not about the accuracy but other problems such as reasoning with who will pay for and who owns the location infrastructure, service and associated data; security and privacy risks, quantifying the value addition, integration into their existing services, supporting various grades of service, etc. This gave me some insight into some problems that several emerging CPS will face, especially when physical components of a networked system become present in spaces owned by one entity, providing services created by other entities, that are consumed by another entity (users). 

\section{Future Work}
My longer term vision is to enable large-scale cyber-physical systems with capabilities for intelligent perception, control, and augmenting the real-word. My goal is for them to interface with humans and have societal impact. They should be mobile and operate in dynamic environments with mobile entities. This is a long-term endeavor spanning several domains. I believe my approach of working across the system stack and solving problems that emerge when we think of systems holistically is suitable to tackle problems towards this. In my dissertation, I have taken the first step step towards this - by building systems, algorithms and tools for taking indoor localization towards a reality. Location is fundamental to these systems that interface with the physical world.  I describe some of my next steps below. 
Building mixed reality systems and the supporting information processing algorithms is my next step towards this vision. Mixed reality enables humans to interact in real-time with the environment. 
These systems necessarily have to be secure and we have to start designing for security from first principles of system design, rather than build systems and then discover and patch the threats as they occur. I want to address problems spanning the co-design of security and the estimation algorithms. Finally these real-time applications demand high bandwidth low-latency communication channels. I am also interested in problems that emerge when location and communication technologies of the future will work together to mutually benefit each other.

 % Location and communication  %real-time 
\paragraph{Emerging applications}

Mixed reality (MR) is exciting and has applications in several domains such as healthcare, manufacturing, entertainment and training.
Both timing and location are fundamental to MR. State-of-art augmented reality (AR) devices rely on high quality visual features. As a result, they take time to initialize the pose and they cannot interact with objects that 
%Though state-of-art augmented reality (AR) devices have made strides in achieving accurate pose estimation, they rely on high quality visual features. As a result, they take time to initialize the pose and they cannot interact with objects that 
are not identified uniquely visually.  %The challenge for MR is State-of-art augmented reality (AR) devices are limited when visual features are poor. They 
I want to develop design principles for fusing multiple sources of information (vision, emerging localization technologies, communication from overhead LEDs) at the low-level to create robust mixed reality systems. % for seamless interaction with the physical world.  
I have shown how we can enhance mobile AR using beacons and magnetic field to improve the pose acquisition \cite{mobileAR}. As a first step, I am currently working on enabling AR interaction with objects by tagging them with tiny LEDs and designing a visible light communication scheme. In future, I want to explore tag-less localization using wireless signals. 

In addition to localization, another challenge in MR that I am interested in solving are managing real-time creation and updates to virtual content associated with physical
objects. %



\paragraph{Security}

Cyber-physical systems are prone to attacks on the physical layer via
access to the environment where the devices are located.  The challenge in detecting attacks at the physical layer signals is that %Since the
%real-world signals are noisy, 
the estimation algorithms allow for
outliers and noisy measurements and the signal models assumed often don't
account for attacks. 
%This makes it hard to detect attacks at the
%physical layer. 
I am interested in understanding how we can integrate
data from physically distributed devices and from multiple sources of
information to make these systems more robust to attacks. As a start
in this direction, I began to analyze this problem space for
range-based localization, with Prof. Sdrjan Capkun's group at ETH
Zurich. 
%One attack model that range-based systems are susceptible to
%at the physical layer is distance enlargement attack. 
Some questions I
am pursuing are - how would the beacon placement in a building change
if we have to guarantee robustness against distance enlargement attacks; can we use
consistency between various sensors and beacon measurements to detect attacks? 
how does the device discovery and MAC layer change based on security
properties of the physical layer? More broadly, I want to draw on my experience of experimentally
working with, and modeling, physical systems to think systematically
about re-designing system models and the estimation algorithms for
making these systems robust to attacks. %We require
%application-specific models as well as across-the-stack approaches for
%making systems secure to physical layer attacks.

%For emerging systems, I want to add 

\paragraph{Next-generation communication}
Last dimension to be optimized is spatial capacity.  At higher frequencies, this requires wireless systems to become heavily location aware. 
Channel modeling, spatial stability of channel.
Location awareness in fifth generation (5G) wireless networks will enable resource allocation by predicting slow-varying channel characteristics and connectivity, and in dynamic spectrum management and routing. 
For mmWave technology physically distributed location-aware devices would coordinate together for beamforming and to create large MIMO arrays. 
Location-awareness can also enable better use of the spectrum by sensing the location of users, and by creating reconfigurable arrays with mobile agents. 
%Location-aware wireless with next generation systems can enable new services for low-power distributed tags, such as those used for asset tracking. 
%For instance wireless energy harvesting localizable tags can be charged by a configuration of drones flying through the space by directing energy at the tags. 
I am also interested in using mmWave and future wireless for simultaneous localization and mapping of environment and objects. 
When localization and communication services mutually co-exist on a device, several design challenges emerge. For instance, determining and quantifying the relationship between the geometry and the communication capacity, trading-off allocation of compute resource for location estimation or communication. To solve these problems, I can draw from my experience in localization, communication and my approach of working across layers of the system stack.  

\section{Additional points}
\textcolor{blue}{Show-off points potentially to add:}\\
Number of alps deployments, size of deployments - several deployments on campus.\\
Worked with Samsung - sensor fusion\\
Samsung fellowship for IoT\\
Mention Terraswarm, CONIX\\
Future automatic mapping of all sensors, devices - best poster at Terraswarm annual meet\\
In MR future work - attended MR workshop at USC\\
Energy meter - worked with EarthSpark in their early days - Haiti deployment\\
NSF BIC project - convention center\\
Industry experience in energy metering embedded back in India?\\
TI internship : PLC WiFi hybrid



%\newpage
\small
\bibliographystyle{abbrv}

\bibliography{references}  % sigproc.bib is the name of the Bibliography in this case

\end{document}
