\documentclass[10pt]{article}

%\usepackage{fancyhdr}
 
%\pagestyle{headings}
%\markright{John Smith}

\date{}

\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{subfigure}  % use for side-by-side figures
\usepackage[colorlinks=true,citecolor=blue]{hyperref}   % use for hypertext links
\usepackage{lipsum}
\usepackage{url}

\usepackage[margin=1in]{geometry}

\usepackage{graphicx}
\usepackage{balance}
\usepackage{comment}
\usepackage{amssymb,amsmath}
\usepackage{caption}
\DeclareCaptionType{copyrightbox}
\usepackage{subfigure}
\usepackage{enumerate}
\usepackage{color}
\usepackage{titling}
%\usepackage{subcaption}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\tableref}[1]{Table~\ref{tab:#1}}

\newcommand{\compactimg}{\vspace{-12pt}}

\clubpenalty=10000 
\widowpenalty=10000
\setlength{\parindent}{0cm}



\begin{document}
\pagenumbering{gobble}

\begin{table}
\color{magenta}
\begin{tabular*}{\textwidth}{l r}
\large\textbf{RESEARCH STATEMENT} & 
\hfill \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 
\large\textbf{NIRANJINI RAJAGOPAL}\\
\hline
\end{tabular*}

\end{table}


We live in exciting times where applications of cyber-physical systems
(CPS) that improve efficiency and safety are emerging. Examples
include interactive experiences with mixed reality, smart and
responsive buildings, autonomous vehicles, smart manufacturing, industrial
internet of things, and computing to improve healthcare. These systems are large in scale, operate in unpredictable environments and have moving parts.  This disrupts classical siloed system design, where systems are broken down into components from different domains, each with their own tools and design methodology. For instance, system implementations are often tuned to the environment or technology. 
This makes it hard to analyze the system for properties such as reliability and
robustness. On the other hand, if we remove properties of the real
world and abstract systems to well-understood models, we can
systematically analyze them and predict their functionality. But this
analysis is far removed from practical systems. To face the challenges of modern CPS, 
%I solves the challenges that arise when we integrate 
%my approach is to identify and solve the challenges that arise across these layers.
I bring to embedded sensing systems research, a systematic understanding of signal processing, system modeling, inference, state estimation and communication. %I identify and solves challenges that arise across these layers  key to building reliable systems that work in the real world. %on challenges that arise when we Sp
I apply tools from signal processing, estimation, optimization to embedded sensing systems.\\
%To build truly reliable and scalable systems that work in the real
%world I adopt an end-end approach spanning
%practical system design and theoretical system analysis.\\


Rather than the traditional siloed approach, I jointly design the sensing pipeline, system models, estimation algorithms and the physical networked embedded system. My methodology is as follows (a) I work closely to the physical layer (b) I experiment and deploy systems in the real-world to understand the interaction between signals and systems from first principles (c) I develop signal, sensor and system models (d) I identify and implement the theoretical tools relevant to the estimation problem (e) I jointly design the cyber system (what
infrastructure to use? where to place them? what sensors to collect
data from? how to schedule the devices? communication schemes) and the
information processing algorithms.

%I identify and solves challenges that arise across these layers, that are key to building reliable systems that work in the real world. %on challenges that arise when we Sp
%I apply tools from signal processing, estimation, optimization to embedded sensing systems. %I common theme across
 %I have worked on several CPS applications end-end %--- energy metering, visible
%light communication and indoor localization; where I  I work across end-end systems 
%spanning communication, time-synchronization, embedded systems, sensing, signal
%processing and estimation layers. %A common theme in my research is
% that I work closely to the sensing layer of CPS systems.
% experiment and to The key is that I I work closely 

% My methodology is the following: I work close to the physical layer. I understand interaction between signals and systems from first principles, through experiments and sensor data analysis. Then I create  models for sensor signals and systems that are general enough to apply theoretical tools but practical in the real world. I

% I do this in the following manner: First, I understand the
% interaction between the cyber and physical system - what sensors can
% be used? what signals can be measured? what is the system we are
% trying to estimate or control? what are the underlying timing
% properties? what parameters affect the system? Then I understand the
% system design constraints - bandwidth, sensor update rate, timing
% requirements, physical resources. Next, I build system and sensor
% models for the cyber-physical interaction from first principles. The
% models are general enough to apply theoretical tools but practical in
% the real world. To develop these, I experiment and deploy systems, and
% understand the theoretical tools relevant to the estimation
% problem. Finally, I jointly design the cyber system (what
% infrastructure to use? where to place them? what sensors to collect
% data from? how to schedule the devices? communication schemes) and the
% estimation algorithms.
% I have worked on several CPS applications --- energy metering, visible
% light communication and indoor localization. I have worked across
% communication, time-synchronization, embedded systems, sensing, signal
% processing and estimation layers. A common theme in my research is
% that I work closely to the sensing layer of CPS systems.



% %My methodology is a combination of experimental , 



% %For instance, system implementation and deployment for the real world is tuned  

% Traditionally system implementation and deployment for the real world is tuned to the environment or technology. 
% This makes it hard to
% analyze the system for properties such as reliability and
% robustness. On the other hand, if we remove properties of the real
% world and abstract systems to well-understood models, we can
% systematically analyze them and predict their functionality. But this
% analysis is far removed from practical systems. 
% To build truly reliable and scalable systems that work in the real
% world I adopt an end-end approach spanning
% practical system design and theoretical system analysis.\\
% To face the challenges of modern CPS, I bring to networked embedded systems research, a systematic understanding of signal processing, system modeling, inference, state estimation and communication. 


% Traditionally, system design is broken down into components belonging to different domains, each with their own tools and methodology. 
% This complexity disrupts classical siloed system design, where systems are broken down with well defined interfaces into hierarchical components belonging to different domains, each with its own tools and design methodology. For instance, 


% Traditionally system implementation and deployment for the real world is tuned to the environment or technology. %are customized for a 
% %to a certain deployment or to the technology. 
% This makes it hard to
% analyze the system for properties such as reliability and
% robustness. On the other hand, if we remove properties of the real
% world and abstract systems to well-understood models, we can
% systematically analyze them and predict their functionality. But this
% analysis is far removed from practical systems. 
% To build 
% %I believe that
% %building 
% truly reliable and scalable systems that work in the real
% world I adopt an end-end approach spanning
% %bring theoretical system analysis to practical
% % requires an end-end approach involving an understanding of
% practical system design and theoretical system analysis.\\

% %This complexity disrupts classical siloed system design, where systems are broken down with well defined interfaces into hierarchical components belonging to different domains, each with its own tools and design methodology.  I believe that
% %building truly reliable and scalable systems that work in the real
% %world requires an end-end approach involving an understanding of
% %practical system design and theoretical system analysis.  I \\%I apply tools from 
% %apply modeling and analysis of signals and systems to systems research. 

% % that is
% %application-specific.
% %These systems
% %are complex and are hard to design. The physical environments that
% %these systems interact with vary with space and time and are hard to
% %model. Therefore, it is challenging to design systems that work well
% %across different environments. 

% %Traditionally, systems that work well in the e\\

% %Often system implementations are tuned
% % to a certain deployment or to the technology. This makes it hard to
% % analyze the system for properties such as reliability and
% % robustness. On the other hand, if we remove properties of the real
% % world and abstract systems to well-understood models, we can
% % systematically analyze them and predict their functionality. But this
% % analysis is far removed from practical systems. 
% % I believe that
% % building truly reliable and scalable systems that work in the real
% % world requires an end-end approach involving an understanding of
% % practical system design and theoretical system analysis.\\

% % I believe that
% % building truly reliable and scalable systems that work in the real
% % world requires an end-end approach involving an understanding of
% % practical system design and theoretical system analysis. % that is
% % application-specific. \\

% To face the challenges of modern cyber-physical systems (CPS), I bring to networked embedded systems research, a systematic understanding of signals, system modeling, inference and . I apply tools from 
% apply modeling and analysis of signals and systems to systems research. \\
% %bring to systems research analysis and modeling of signals and systems.

% my work spans embedded systems, communication systems, sensing, and signal processing and estimation algorithms. I bring to the systems research community an understanding
% My approach is to jointly design 
% I work close to the physical layer. I \\

% across the CPS stack of embedded systems, communication, and signal processing and estimation. I 
% I work at the physcial layer of sensing, communication and time-synchronization and \\


% %My research answers questions on systematic design of CPS and
% %I design networked embedded systems that interface to the real-world through sensors and actuators, also called cyber-physical systems (CPS). 

% %\paragraph{My approach:}
% %My approach to CPS design is to jointly design the sensing pipeline, estimation
% %algorithms, system models, and the physical networked embedded
% %system. A common theme my work 


% Rather than the traditional siloed approach, I jointly design the sensing pipeline, system models, estimation algorithms and the physical networked embedded system. %My methodology is a combination of experimental , 

% I work close to the physical layer to first understand the interaction between the cyber and physical systems. 

% I do this in the following manner: First, I understand the
% interaction between the cyber and physical system - what sensors can
% be used? what signals can be measured? what is the system we are
% trying to estimate or control? what are the underlying timing
% properties? what parameters affect the system? Then I understand the
% system design constraints - bandwidth, sensor update rate, timing
% requirements, physical resources. Next, I build system and sensor
% models for the cyber-physical interaction from first principles. The
% models are general enough to apply theoretical tools but practical in
% the real world. To develop these, I experiment and deploy systems, and
% understand the theoretical tools relevant to the estimation
% problem. Finally, I jointly design the cyber system (what
% infrastructure to use? where to place them? what sensors to collect
% data from? how to schedule the devices? communication schemes) and the
% estimation algorithms.
% I have worked on several CPS applications --- energy metering, visible
% light communication and indoor localization. I have worked across
% communication, time-synchronization, embedded systems, sensing, signal
% processing and estimation layers. A common theme in my research is
% that I work closely to the sensing layer of CPS systems.


% My approach to CPS design is to jointly design the estimation
% algorithms, system models, and the physical networked embedded
% system. I do this in the following manner: First, I understand the
% interaction between the cyber and physical system - what sensors can
% be used? what signals can be measured? what is the system we are
% trying to estimate or control? what are the underlying timing
% properties? what parameters affect the system? Then I understand the
% system design constraints - bandwidth, sensor update rate, timing
% requirements, physical resources. Next, I build system and sensor
% models for the cyber-physical interaction from first principles. The
% models are general enough to apply theoretical tools but practical in
% the real world. To develop these, I experiment and deploy systems, and
% understand the theoretical tools relevant to the estimation
% problem. Finally, I jointly design the cyber system (what
% infrastructure to use? where to place them? what sensors to collect
% data from? how to schedule the devices? communication schemes) and the
% estimation algorithms.
% I have worked on several CPS applications --- energy metering, visible
% light communication and indoor localization. I have worked across
% communication, time-synchronization, embedded systems, sensing, signal
% processing and estimation layers. A common theme in my research is
% that I work closely to the sensing layer of CPS systems.

%A large part of my work has been on applications for mobile devices. 

% \textbf{Contributions to fundamental research:}\\
% My research is grounded in 
% I have worked on several CPS applications - energy metering, visible light communication and indoor localization. I have worked across communication, time-synchronization, embedded systems, sensing, signal processing and estimation layers. 

% \textbf{Understanding}\\
% I want to build reliable systems that work in the real-world. I also take efforts to understand end applications and users. For instance, after working on indoor localization and \\

%\textbf{Impact:}\\

%I highlight some characteristics of my research style with examples of my work in CPS applications of energy metering, visible light communication and indoor localization\\
%\textbf{Modeling from first principles: }
%\textbf{Problem-oriented research: }\\

%\textbf{Collaboration with external organizations: }

\paragraph{Impact:}  In 2013, when LED lights were phasing out
incandescent lights, I designed one of the earliest visible light
communication (VLC) systems to send data from overhead LED lights and
for light-based localization. This work was published in IPSN'14
(cited 130+ times), VLCS'14 and demonstrated in IPSN'14.  My
dissertation contributed to beacon-based indoor localization systems
for mobile devices, and resulted in several publications (SenSys'15,
RTAS'15, IPIN'16, IPSN'18, two under submission, demonstrations at
Sensys'15, IPSN'18), received 2 patents, won the international
Microsoft Indoor Localization competition twice, received a best demo
award, spawned a startup, and has led to funding from NSF, SRC, NIST, and
industry. This work is being applied to indoor navigation, mobile
persistent augmented reality, firefighter localization, and asset
mapping applications.  I have also contributed to other areas of CPS:
time-synchronization (RTSS'14, RTAS'17) and electrical energy
monitoring (ICCSP'13, demonstrated at ICCPS'13).

\section{Current Research}

My dissertation is on indoor localization - an instance of a CPS problem. Location is also an important service for other CPS applications.

There are more than a million papers on indoor localization. Yet we get lost indoors today. The reason is --- we don't have solutions that are free-of-cost, do not require any environment-specific setup, are accurate, reliable and instant (do not require the user to walk around some distance). Existing solutions that are free-of-cost use a fusion of signals from WiFi, and on-board sensors such as camera and inertial sensors. But they require environment-specific mapping and are not instant. Solutions that deploy infrastructure can be accurate and instant if sufficient infrastructure (beacons or anchors) are in line-of-sight. A device localizes itself with respect to beacons by using signaling a range-based measurement technique (time-of-flight, time-difference-of-arrival, angle-of-arrival). However, this system is not free since we have to install beacons densely across buildings, and setup and map them. \\

\textbf{Platform and ranging technologies:} I argue that in the future, ranging capability will be available on commodity devices, WiFi access points, IoT devices and possibly smart appliances. %all devices that require localization service. 
Time-of-Flight (ToF) ranging is emerging through various wireless standards. % and is getting integrated into commodity devices, WiFi access points, and IoT devices. I believe that in future,  
The emerging technologies include mmWave, ultra-wideband (including emerging 802.18.4z), WiF 802.11mc and BLE5. On the platform side I contributed to building an ultrasonic platform that localizes unmodified mobile devices. The ultrasonic beacons harvest energy from overhead lights, are synchronized using 802.15.4 and use BLE advertisement packets to synchronize mobile devices
\cite{rtas-alps-platform, lazik2015alps,lazik2015alpsdemo}. I interned at Apple's wireless location group and worked with their earliest versions of WiFi ToF, which subsequently got rolled into the next generation products. I am collaborating with Texas Instruments on BLE5 ToF ranging. 

%I envision that in future %their and my work with their propreitary WiFi-based ToF 
My strategy was to adopt time-of-flight ranging paradigm and built the tools required to make ToF localization accurate and instant with low beacon density, and create tools for automatic beacon placement and mapping. %not be constrained by what technologies are available today. Time-of-flight is 

% % These beacons -based approaches that provide a range measurement  can we accurate and instant if sufficient 

% % These include infrastructure-free approaches using data from on-board inertial sensors, camera and floor plans; and infrastructure-based approaches by estimating a range based on some signaling method such as signal strength time-of-flight, time-difference-of-arrival, angle-of-arrival to the infrastructure. Across these methods, there is a trade-off between accuracy, time-to-first-fix, and cost of hardware, and effort and time to calibrate and setup the system for an environment. % infrastructure and effort for setup, mapping and managing Ideally, we
% % %want accurate and instant location and orientation acquisition on
% % %mobile devices with as minimal infrastructure as possible.% ti infrastructue vision and inertial sensors; and infrastructure-Across them 

% % Infrastructure-based systems can provide accurate localization if there are sufficient
% % number of anchors or beacons in line-of-sight. However this requires a
% % dense deployment, which is impractical at building scale.  My
% % dissertation solves these problems with an end-end approach for
% % range-based localization.


% \paragraph{Abstracting the technology: }
%  The first
% question I asked was - what model can I create that apply to a class
% of practical technologies, yet is general enough? The answer to that
% question was to abstract the signaling between beacons and the device
% being localized as time-of-flight ranging.
% %how can I abstract the localization technology such that it is practical, yet generalize the  generalize across a variety of technologies? 
% %An important question The first question that comes up with infrastructure-based localization is 
% I contributed to building an ultrasonic platform that localizes
% unmodified mobile devices. The ultrasonic beacons harvest energy from
% overhead lights, are synchronized using 802.15.4 and use BLE
% advertisement packets to synchronize mobile devices
% \cite{rtas-alps-platform, lazik2015alps,lazik2015alpsdemo}. Next, I
% interned at Apple's wireless location group and experimented with
% early prototypes of custom ToF ranging over WiFi, for device-device
% ranging which eventually resulted in product impact. Subsequently, I
% worked with ultra-wideband ToF ranging and I am currently working with
% Texas Instruments on early prototypes of BLE ToF ranging. Other
% emerging standards are 802.15.4z and 802.11mc and mmWave technology. I
% believe that these trends in academia and industry are pushing ToF
% ranging on commodity devices, WiFi access points and low power
% tags. Hence, my approach was to adopt time-of-flight ranging as a
% paradigm that generalizes across several technologies.

%I then solved the problems that developed the necessary tools and solve problems that these emerging technologies face. 
%Hence, my approach was to I first built a ranging technology, then took the effort to experiment with and understand other emerging ranging technologies and  used range-based for the rest of my dissertation built the tools that will enable our goal of accurate instant localization possible with these technologies. I abstracted away the technology and used range-based paradigm. I argue that emerging trends in academia and industry and pushing ranging technology to commodity devices, WiFi access points and low power tags.  and will become part of our indoor infrastructure in the future. 

%The answer I arrived at was, time-of-ranging was a paradigm that generalized to several technologies.

\paragraph{A robust location-solver: }
ToF systems require high density beacon coverage and suffer from incorrect measurements due to
non-line-of-sight (NLOS) signals. 
% that reflect off surfaces where there isn't a direct path between the beacon and the device being localized. 
In realistic conditions, the user has walk around for the system to gather more measurements and converge. After facing this problem in several real-world deployments, I wanted to create a robust solver that localized instantly and accurately, with minimal LOS measurements and was robust to NLOS measurements. 

I solved this problem with a new idea that is simple and effective in practice \cite{rajagopal2018enhancing}. 
I compute the LOS coverage region for each beacon by using the floor plan geometry and a ray tracing model for beacon coverage. Rather than using low-level signal statistics or temporal information (both defeat the purpose of the instant solver), or assume knowledge of NLOS signal path (infeasible in practice), I assume that the NLOS signal travels a longer path than the LOS signal (which is true for all ranging technologies). The key innovation in the solver is that I also use the absence of measurement from certain beacons as useful information. I designed a hypothesis-testing floor-plan aware solver that checks for consistency between the received and absent measurements and the beacon coverage model.

This solver is the first that localizes with just two LOS beacons, rather than three (for 2D localization), and maintains the same performance even when several NLOS signals are present. Across several real
world environments, this solver detected and removed NLOS with 91\% accuracy and maintained 1m accuracy as compared to 4-8m by traditional approaches. We implemented this
method in our system that won the Microsoft Indoor
Localization Competition in 2015. 

\paragraph{A systematic beacon placement approach: }
Anyone who has deployed a localization system at building-scale with a limited budget for beacons faces the challenge of not knowing where to place them. % and how to optimize the placement. 
Hence, more beacons than necessary are deployed and some amount of domain expertise is required for placing beacons. 

%The localization performance depends on where we placed the beacons. So 
I designed beacon placement algorithms in a
MATLAB-based toolchain available on GitHub, where users can draw or provide real world floor plans. They can
then try out different beacon placements and compare them quantitatively \cite{rajagopal2016beacon}. 

I used the insights from the floor-plan aware solver to design a placement algorithms. % that would  beacon placement. I used my insights from the floor-plan awa
%My insight from the floor-plan aware solver was that beacon placement and localization performance I used my insights from the floor-plan aware solver to deploy beacons such that we can  beacon placement 
%The localization performance depended on where we placed the beacons and we . go hand-in-hand and we can reduce the number of beacons and  I could deploy beacons in a manner such that the estimation performance is a function of the beacon placement and I could use I could co-design the deploy beacons in a smart manner With the floor-plan aware solving approach, I could now co-designing
%beacon placement and the estimation algorithm, we can reduce the
%number of beacons and improve robustness of the location solving
%algorithm.
%Next, I used the insights from the floor-plan aware location solver 
%I wanted to created an automated beacon placement toolchain that could systematically suggest beacon locations and leverage the insights from the floor-plan aware solver to minimize the number of beacons \cite{rajagopal2016beacon}. 
I define a location to be uniquely localizable if the location is covered by three or more beacons, or if it is covered by two beacons and the other location with the exact same distances from the two beacons has a different beacon set coverage. I designed a greedy beacon placement algorithm that optimizes for area that is uniquely localizable.  The algorithm reduced the number of beacons by $33\%$ compared to minimal placement with 3-beacon coverage across real-world and simulated floor plans. %In reality, we care about accuracy rather than only coverage. %coverage doesn't give us an idea about the accuracy 
To account for accuracy in addition to coverage, I adopted the Cramer-Rao lower bound on the location estimate. This depends on the geometric dilution-of-precision (GDOP) - an analytical function of the angles between the beacons and the location; and standard deviation assuming additive Gaussian noise model for ranging error. I use the GDOP and the unique localization function over all regions to generate an expected CDF from any deployment, and design a second greedy beacon placement algorithm that optimizes for expected accuracy.  %  The toolchain compares the
%users placement with the two algorithms.

%\cite{rajagopal2016beacon

I extended this work in collaboration with
Prof. Jie Gao from Stony Brook and her student. We mathematically
formulated the beacon placement problem for unique localization and proposed placement
algorithms with provable guarantees \cite{beaconplacementtheory}. Such systematic approaches and automated tools for beacon
placement are necessary while scaling up these systems from labs to
building-scale. %I defined the notion of unique localization, where a location is uniquely localized if it can be localized  ambiguity by two or more beacons.

Through these two works, my approach was to understand the interaction between ranging signals and real-world environments from first principles, design models of signals (LOS, NLOS), and systems (floor plan, beacon coverage) that were close to practical and general enough to systematically analyze. I used these principles to design the deployment of the system. 

%coverage. In reality, we care about accuracy,  and suggest an efficient beacon placement and compare the effectively of various possible placements. There was no way to quantify the effectiveness of a beacon placement
%sThe main challenge while depoying beacons is that nobody knows where exactly to palce them  system installers face is they don't know
%where to place the beacons. Indoor spaces are complex and there is no
%systematic way to place beacons.  

% \cite{rajagopal2016beacon}

% To quantify the accuracy given by a beacon configuration, I adopted
% the Cramer-Rao lower bound on the location estimate.  This is
% dependent on the geometry of beacons, given analytically by the
% geometric-dilution-of-precision (GDOP).  I combine the coverage and
% GDOP to quantify and compare different beacon configurations. I then
% designed beacon placement algorithms for minimizing beacons -
% maximizing for either coverage, or accuracy. This is implemented in a
% MATLAB-based toolchain available on GitHub, where users can draw floor
% plans, or provide real world floor plans as an input. The users can
% then try out different beacon placements.  The toolchain compares the
% users placement with the two algorithms. The proposed technique
% reduced the number of beacons by $33\%$ on an average across real and
% simulated floor plans, as compared to typical 3-beacon coverage
% placement. I further extended this work in collaboration with
% Prof. Jie Gao from Stony Brook and her student. We mathematically
% formulated the beacon placement algorithm and proposed placement
% algorithms with provable guarantees \cite{beaconplacementtheory}. I
% believe that such systematic approaches and automated tools for beacon
% placement are necessary while scaling up these systems from labs to
% building-scale.


%indoor spaces are provisioned with too many beacons. 
%This works in lab and smaller spaces but doesn't scale. 
%Often we have a limited number of beacons and somehow have to optimize where to place them. %There was no systematic way to compare two potential beacon configurations. 

% So, the next question I asked is - Can we determine the minimal beacon
% placement for ToF localization, and create tools to suggest beacon
% locations? The norm is to localize using three beacons for 2D.  I
% proposed a new and simple idea to localize with two beacons
% \cite{rajagopal2016beacon}. I model the floor plan as polygons and the
% beacon coverage using ray tracing. I then use the floor plan and the
% absence of measurements from beacons as additional information, to
% distinguish between two possible solutions we get while localizing
% with two beacons. This model is general enough to analyze
% systematically and also works in practice.




%This is an example of my appraoch where I designed the end-end pipeline from sensing, system models and estimation. To complete th 

%I then use the absence of measurements as additional informaiton to We  the floor plan as polygons, using the floor plan geometry, ray tracing. I designed a floor-plan aware location solver that used the beacon coverage model in addition to the range measurements to compu

%Then I modeled the NLOS  and ray I modeled the floor plan geometrically and used  and as  the floor plan geometry and modeled the coverage of beacons 

 %To build robustness against NLOS signals,
%one approach is to deploy many beacons. A more common approach is -
%the system does not converge on a location estimate unless the user
% walks around, and more measurements are gathered. However, we want
% instant location acquisition. So the next question was - Can we
% compute the location accurately in the presence of a large number of
% NLOS signals? To solve this, I built on the floor-plan aware approach
% and designed a location solver by partitioning the floor plan into
% regions covered by different set of beacons
% \cite{rajagopal2018enhancing }. I then designed a hypothesis testing
% solver than checks for consistency between possible physical
% locations, the beacon coverage model and the NLOS model. The NLOS
% model I used was that a NLOS signal is positively biased. This model
% generalizes across ranging technologies and environments.  The solver
% then detects and prunes out NLOS ranges and estimates a location. This
% method was implemented in our system that won the Microsoft Indoor
% Localization Competition in 2015. We evaluated it in several real
% world environments and we were able to maintain 80\% localization
% accuracy from 4-8m to 1m in low-beacon density and NLOS conditions. We
% are able to detect and remove NLOS signals with 91.5\% accuracy.

 % making assumptins on the particular path that the signal takes. 

%The main insights from these two works is that the absence of
% information, such as not receiving a measurement from a beacon, is
% also useful information. The second insight is that by co-designing
% beacon placement and the estimation algorithm, we can reduce the
% number of beacons and improve robustness of the location solving
% algorithm.



% \paragraph{A systematic approach to deployment: }

% One of the main challenges system installers face is they don't know
% where to place the beacons. Indoor spaces are complex and there is no
% systematic way to place beacons.  As a result, more beacons than
% necessary are deployed.

% %indoor spaces are provisioned with too many beacons. 
% %This works in lab and smaller spaces but doesn't scale. 
% %Often we have a limited number of beacons and somehow have to optimize where to place them. %There was no systematic way to compare two potential beacon configurations. 

% So, the next question I asked is - Can we determine the minimal beacon
% placement for ToF localization, and create tools to suggest beacon
% locations? The norm is to localize using three beacons for 2D.  I
% proposed a new and simple idea to localize with two beacons
% \cite{rajagopal2016beacon}. I model the floor plan as polygons and the
% beacon coverage using ray tracing. I then use the floor plan and the
% absence of measurements from beacons as additional information, to
% distinguish between two possible solutions we get while localizing
% with two beacons. This model is general enough to analyze
% systematically and also works in practice.

% To quantify the accuracy given by a beacon configuration, I adopted
% the Cramer-Rao lower bound on the location estimate.  This is
% dependent on the geometry of beacons, given analytically by the
% geometric-dilution-of-precision (GDOP).  I combine the coverage and
% GDOP to quantify and compare different beacon configurations. I then
% designed beacon placement algorithms for minimizing beacons -
% maximizing for either coverage, or accuracy. This is implemented in a
% MATLAB-based toolchain available on GitHub, where users can draw floor
% plans, or provide real world floor plans as an input. The users can
% then try out different beacon placements.  The toolchain compares the
% users placement with the two algorithms. The proposed technique
% reduced the number of beacons by $33\%$ on an average across real and
% simulated floor plans, as compared to typical 3-beacon coverage
% placement. I further extended this work in collaboration with
% Prof. Jie Gao from Stony Brook and her student. We mathematically
% formulated the beacon placement algorithm and proposed placement
% algorithms with provable guarantees \cite{beaconplacementtheory}. I
% believe that such systematic approaches and automated tools for beacon
% placement are necessary while scaling up these systems from labs to
% building-scale.
%  %through a GUI or used the suggested placement by the algorithm. 
%  % to deploy beacons in a smart manner and 
%  % to non-line-of-sight signals from beacon nearby.  

% \paragraph{Robust location solver:}
% Range-based systems are prone to incorrect measurements due to
% non-line-of-sight signals. To build robustness against NLOS signals,
% one approach is to deploy many beacons. A more common approach is -
% the system does not converge on a location estimate unless the user
% walks around, and more measurements are gathered. However, we want
% instant location acquisition. So the next question was - Can we
% compute the location accurately in the presence of a large number of
% NLOS signals? To solve this, I built on the floor-plan aware approach
% and designed a location solver by partitioning the floor plan into
% regions covered by different set of beacons
% \cite{rajagopal2018enhancing }. I then designed a hypothesis testing
% solver than checks for consistency between possible physical
% locations, the beacon coverage model and the NLOS model. The NLOS
% model I used was that a NLOS signal is positively biased. This model
% generalizes across ranging technologies and environments.  The solver
% then detects and prunes out NLOS ranges and estimates a location. This
% method was implemented in our system that won the Microsoft Indoor
% Localization Competition in 2015. We evaluated it in several real
% world environments and we were able to maintain 80\% localization
% accuracy from 4-8m to 1m in low-beacon density and NLOS conditions. We
% are able to detect and remove NLOS signals with 91.5\% accuracy.

%  % making assumptins on the particular path that the signal takes. 

% The main insights from these two works is that the absence of
% information, such as not receiving a measurement from a beacon, is
% also useful information. The second insight is that by co-designing
% beacon placement and the estimation algorithm, we can reduce the
% number of beacons and improve robustness of the location solving
% algorithm.

\paragraph{Tracking and mapping}
I fused beacon ranges with visual-inertial odometry on phones with a Particle Filter approach. This implementation won the Microsoft Indoor Localization competition in 2018 with ultra-wideband beacons. The next problem we solved was automatic beacon mapping. In future, when WiFi access points, IoT devices and mobile devices have ranging capabilities, devices that are stationary can begin to act as beacons, and have to be mapped in real-time. Beacon mapping is also applicable for applications like asset mapping. I implemented a Rao Blackwellized-based Range-only Simultaneous Localization and Mapping algorithm to perform automatic beacon mapping by a pedestrian simply walking around holding a phone. 

\paragraph{Orientation acquisition and mobile augmented reality }

While most indoor localization work focuses on location
estimation, orientation is necessary for applications like mobile
augmented reality. %Existing approaches either rely on visual features
%or require the user to walk around for some distance before the
%orientation can be acquired.
I designed a novel approach where we fused Visual
Inertial Odometry and beacons to crowd-source a dense magnetic field
map with pedestrian-held phones. Subsequently, future users use this map at startup to calibrate
their compass in order to instantly estimate orientation. %Though
%magnetic field has been shown to be promising for localization, 
This is the first phone-based system that shows the feasibility of using magnetic field for
for instant orientation acquisition. %We also automatically map the beacon
%infrastructure as the pedestrian walks around with a phone.  
We used
this system to build and end-end multi-user persistent augmented
reality system that works in any environment without requiring the
sharing of large and often fragile point-cloud maps \cite{mobileAR}. This work won best demo award at IPSN 2018 \cite{rajagopal2018welcome}. This system is implemented on our ultrasonic localization system that spawned into a startup. It has been deployed in a retail for AR-based product finding. 

In these two works, I analyzed the magnetic field spatial and temporal variation at the physical layer, created models and designed algorithms for location acquisition, tracking and mapping algorithms, and used these to build an end-end mobile AR application. 
%The main insight from this work was that a sensor fusion approach of
%camera, inertial sensors, magnetic field and beacons can

% \paragraph{Orientation acquisition:}

% The third problem I addressed was orientation acquisition on mobile
% devices. While most indoor localization work focuses on location
% estimation, orientation is necessary for applications like mobile
% augmented reality. Existing approaches either rely on visual features
% or require the user to walk around for some distance before the
% orientation can be acquired.

%  %Most existing systems estimate the orientation by requiring the user
%  %to walk around for some distance, or relying on visual features in
%  %the environment.  %that is required for mobile Augmented Reality
%  %still remains a challenge.

% We designed a novel approach where we used a combination of Visual
% Inertial Odometry and beacons to crowd-source a dense magnetic field
% map. Subsequently, future users use this map at startup to calibrate
% their compass in order to instantly estimate orientation. Though
% magnetic field has been shown to be promising for localization, this
% is the first phone-based system that shows the feasibility of using it
% for orientation acquisition. We also automatically map the beacon
% infrastructure as the pedestrian walks around with a phone.  We used
% this system to build and end-end multi-user persistent augmented
% reality system that works in any environment without requiring the
% sharing of large and often fragile point-cloud maps
% \cite{rajagopal2018welcome}.

% The main insight from this work was that a sensor fusion approach of
% camera, inertial sensors, magnetic field and beacons can

% \paragraph{Mapping and Tracking}:

%The algoethims I proposd worked well but di not have any theoretical
%guarantees. I explored preliminary theoretical results using
%computational geometry. To take this work forward, I collaborated
%with Prof. jie Gao's group iFrom Stony Brook University. We now have
%two beacon placement algorithms with theoretical guarantees thatis
%implemetned and availael on the oolchain. these algorithms palce 33\%
%fewer beacons than typical placemnts, and \% more than minimal
%placement using our uniwur localiation approahc. This is th first
%work that analyzes minimal bacon palcemtna nd uautoatic beacons
%palcement for ToF localtiz. I believe such automated tools will
%simple system installt. \\

% \paragraph{Future localization ecosystem}
\paragraph{End Users} 
There is no silver bullet for a localization architecture. % localization architecture 
We am working with National Institute of Standards and Technologies (NIST) on the challenging problem of localizing firefighters during an operation. Here, we cannot rely on any existing beacons inside the building. Our solution has a combination of fixed beacons on firetrucks; firefighters with wearable devices; and estimation algorithms based on mobile network localization. We are exploring the possibility of the exit signs on buildings becoming potential locations for low-power beacons that operate in emergencies. In future, I would integrate a network of drones with this architecture to make the communication and localization more resilient.%It is likely that in future we would have different grades of reliabiity in localization technologies, some for emergency\\

I recently participated in a conference on mobile positioning for museums. My goal was to understand one use case in depth. Some of my learnings from this deep dive into one segment was that performance is not the key problem, but the bigger problems are reasoning with who will pay for and who owns the location infrastructure, service and associated data; security and privacy risks, quantifying the value addition, integration into their existing services, supporting various grades of service, etc. This gave me some insight into some problems that several emerging CPS will face, when physical components of a networked system become present in spaces owned by one entity, providing service created by other entities, that are used by another entity. 
%ultrabeacons on firetrucks that drive up to the site; firefighters have wearable devices with 
%The system design here has to adapt to

% I am 
% I envision that the future indoor localization ecosystem will have a combination of support for emergency applications and user applications. \\
% The fixed infrastructure would be part of support for emergency services. The mobile infrastructure would be part of commodity devices such as mobile devices\\
% Talk about NIST\\
% Talk about TI and asset tracking\\
% Talk about IoT paradigm\\
% I recently participated in a conference on mobile positioning for museums. My goal was to understand one use case in depth. I learnt from the conference that 

%Localization for emergency applications could be the enbais challenging since we cannot rely on existing 

\subsection{Other CPS areas}
Though not the focus of my dissertation, I worked on building end-end visible light communication systems. 
LED lights turn on and off at a high frequency, offering an opportunity to use them as a communication channel to send data to mobile devices. The main challenge is that the lights operate at a much higher frequency than the camera frame rate.%But the lights
%operate at a bandwidth that is orders of magnitude higher than the
%camera's frame rate.
To communicate data despite this limitation, I designed a novel
sensing approach to exploit the low-level rolling-shutter effect of camera sensors 
on phones to capture a time-varying light signal as a spatially varying image \cite{rajagopal2014visual, rajagopal2014demonstration}. %detect a high frequency light signal and used this to
I designed a modulation scheme that supported multiple lights.  
%A
%practical challenge was in maintaining performance when the user holds
%the phone normally, rather than pointing at the light. To overcome
%this, 
To make the system robust to real-world applications, I modeled the exposure and focus control of the camera as
filters that respond differently to the light signal and the scene
captured to improve the signal-to-noise ratio. %This
%was one of the earliest systems for LED camera communication using the rolling shutter effect
We extended the work
\cite{rajagopal2014hybrid} to design a hybrid communication scheme
where a single light transmits two independent data streams at
different data rates simultaneously to a phone and a photo-diode. I
presented this in the first Visible Light Communication
(VLC) workshop. Subsequently, the field of
VLC has grown significantly with several rolling-shutter based
approaches for communication and localization, in both academia and
start-ups. Our work was one of the earliest works in LED-camera communication and using VLC for
localization.

%The main insight from this work was that we can design a new
%communication system using existing infrastructure by using the
%filtering properties of cameras.




I also worked on problems in time-synchronization \cite{buevich2013hardware,
  dongare2017pulsar, rtas-alps-platform}, and non-intrusive load-disaggregation using a sensor network of electromagnetic field sensors \cite{rajagopal2013magnetic, rajagopal2013demo}

%I have also worked on CPS applications of energy metering and visible
%light communication. %using a sensing approach. The challenge across
%these applications is in system design that achieves performance with
%limited resources. \\
 
%\textbf{Energy metering}:\\
%While I worked in industry on designing embedded energy metering products for the smart grid. % that monitor aggregated energy 
%Though we can measure aggregated energy, it is hard to dis-aggregate individual appliances without using plug-in meters for each appliance. 

% One of the CPS applications I worked on was dis-aggregation of
% individual appliances within a home.  To solve this, we proposed a
% contactless battery-operated electromagentic field (EMF) sensors that
% we deployed near each appliance. We modeled each appliance as a
% two-state device, and designed an estimation algorithm that integrated
% data from the EMF sensors and the whole house energy meter
% \cite{rajagopal2013magnetic, rajagopal2013demo}. The main insight here
% was that despite each appliance having a unique energy consumption
% pattern, and we could use novel sensing, along with a simple model and
% time-synchronization to solve this hard problem.


% We designed contactless battery-operated electromagentic field (EMF)
%sensors that we deployed near each appliance. This sensor detected
%appliance state transitions based on magnetic and electric field
%fluctuations. We modeled each appliance as a two-state device and
%designed an algorithm for load-disaggegation using the data from
%magnetic field sensors and whole house energy meter \.  Working with
%energy metering and the electrical infrastructure of homes, a
%question that emerged was can we opportunistically use the power
%lines as a communication channel indoors?  To explore this question,
%I interned at Texas Instruments Communications and Systems Lab and
%designed a power line communication-WiFi hybrid communication scheme
%in simulation at the MAC and PHY layer.\\

%\textbf{Visible Light Communication}:\\ 

%The next question that emerged was, even if the PLC could be used as a backbone infrastructure, how can we communicate data from the electrical infrastructure to mobile devices? This question was timely, as back in 2013, LED lights were starting to phase out incandescent lights, and it was clear that LED lights will become pervasive in the future indoor infrastructure. LED lights turn on and off at a high frequency. 

%Another CPS application I have worked on in visible light communication from overhead LEd lights. 

%Back in 2013, LED lights were starting to phase out incandescent lights. It was clear that LED lights will become pervasive in the future indoor infrastructure and this was an opportunity. 
%The challenge was that the lights had a operate at a higher bandwidth than the for the lights to be flicker-free, they have to be modulated at a frequency much higher than the camera frame rate. 

% LED lights turn on and off at a high frequency. This is was an
% opportunity to use them as a communication channel. But the lights
% operate at a bandwidth that is orders of magnitude higher than the
% camera's frame rate.


% To communicate data despite this limitation, I designed a novel
% sensing approach that exploited the rolling-shutter effect of cameras
% on phones to detect a high frequency light signal and used this to
% design a modulations scheme that supported multiple lights.  A
% practical challenge was in maintaining performance when the user holds
% the phone normally, rather than pointing at the light. To overcome
% this, I modeled the exposure and focus control of the camera as
% filters that respond differently to the light signal and the scene
% captured and used this to improve the signal-to-noise ratio. This
% system was one of the earliest systems to show that we can send data
% from overhead LED lights to phones using the rolling shutter effect
% \cite{rajagopal2014visual}.  We demonstrated this system
% \cite{rajagopal2014demonstration} and also extended the work
% \cite{rajagopal2014hybrid} by designing a hybrid communication scheme
% where a single light transmits two independent data streams at
% different data rates simultaneously to a phone and a photo-diode. This
% hybrid system was presented in the first Visible Light Communication
% (VLC) workshop. Subsequently, over the past four years the field of
% VLC has grown significantly with several rolling-shutter based
% approaches for communication and localization, in both academia and
% start-ups. Our work was on of the earliest works in using VLC for
% localization.

% The main insight from this work was that we can design a new
% communication system using existing infrastructure by using the
% filtering properties of cameras.


%I have worked on several CPS applications - energy metering, visible light communication and indoor localization. I have worked across communication, time-synchronization, embedded systems, sensing, signal processing and estimation layers. 

\section{Future Work}
My longer term vision is to build large-scale autonomous intelligent cyber-physical systems around sensing, perception and mobility, that have societal impact. Some of my next steps in this direction towards next generation spatial-aware systems, making systems more secure and integration with future communication technologies are: %The complexity and
%dynamics of the real-world makes this space challenging and
%interesting.

% that work reliably and are secure. 
%I am looking forward to collaborating with industry and researchers in diverse domains to solve problems in this space.

\paragraph{Emerging applications}
Mixed reality (MR) is exciting and has applications in several domains such as healthcare, manufacturing, entertainment and training.
Both timing and location are fundamental to MR. State-of-art augmented reality (AR) devices rely on high quality visual features. As a result, they take time to initialize the pose and they cannot interact with objects that 
%Though state-of-art augmented reality (AR) devices have made strides in achieving accurate pose estimation, they rely on high quality visual features. As a result, they take time to initialize the pose and they cannot interact with objects that 
are not identified uniquely visually.  %The challenge for MR is State-of-art augmented reality (AR) devices are limited when visual features are poor. They 
I want to develop design principles for fusing multiple sources of information (vision, emerging localization technologies, communication from overhead LEDs) at the low-level to create robust mixed reality systems. % for seamless interaction with the physical world.  
I have shown how we can enhance mobile AR using beacons and magnetic field to improve the pose acquisition \cite{mobileAR}. As a first step, I am currently working on enabling AR interaction with objects by tagging them with tiny LEDs and designing a visible light communication scheme. In future, I want to explore tag-less localization using wireless signals. 
%As next steps,  LEDs, such as . 
%We could also
%potentially use visible light-based localization using overhead LED
%lights since AR devices have cameras. 
%with analysis of wireless channel at the physical layer. 
%The emerging localization technologies and low
%power tags will be key to MR interaction with devices. 
In addition to localization, another challenge in MR that I am interested in solving are managing real-time creation and updates to virtual content associated with physical
objects. %


%The emerging localization technologies and low
%power tags will be key to MR interaction with devices. We could also
%potentially use visible light-based localization using overhead LED
%lights since AR devices have cameras. I want to develop design
%principles for fusing these sources of information at the
% low-level.
% State-of-art augmented reality (AR) devices have limitations in environments with poor visual features and cannot interact with devices heavily rely on receiving high-quality vision features. %use
% %vision and inertial sensors to estimate the pose of the display device
% %(headset or mobile device) with respect to the environment. However,
% %this is not sufficient for several reasons. Vision suffers in
% highly-dynamic or low-light environments. As a result, upon startup
% the user has to walk around or move some distance. Vision also suffers
% when it encounters identical looking visual features that are in
% different locations. 
% I have shown how we can enhance mobile AR using
% beacons and magnetic field to improve the pose acquisition \cite{} and
% that we can interact with physical objects by attaching tags that are
% localized by beacons. 
% The emerging localization technologies and low
% power tags will be key to MR interaction with devices. We could also
% potentially use visible light-based localization using overhead LED
% lights since AR devices have cameras. I want to develop design
% principles for fusing these sources of information at the
% low-level. To associate virtual content with physical objects, we have
% to identify them uniquely. While this can be done by adding visual
% markers to objects, this is not desirable. I want to explore tag-less
% localization using ambient signals, either based on light or
% wireless. As a first step towards interacting with objects in the
% environment, I am collaborating on a project to discover AR content on
% devices tagged with LEDs. 
% In addition to localization, other
% challenges in MR that I am interested in solving are managing the infrastructure that supports
% interaction, managing the virtual content associated with physical
% objects, and real-time updates to virtual content through physical
% interfaces.

% Mixed reality (MR) is exciting and has applications in several domains
% such as healthcare, manufacturing, entertainment and training. %In
% %these MR applications users interact with physical things and devices
% %in their environment in real-time.  
% Both timing and location are
% fundamental to MR. 
% %State-of-art augmented reality (AR) devices use
% vision and inertial sensors to estimate the pose of the display device
% (headset or mobile device) with respect to the environment. However,
% this is not sufficient for several reasons. Vision suffers in
% highly-dynamic or low-light environments. As a result, upon startup
% the user has to walk around or move some distance. Vision also suffers
% when it encounters identical looking visual features that are in
% different locations. I have shown how we can enhance mobile AR using
% beacons and magnetic field to improve the pose acquisition \cite{} and
% that we can interact with physical objects by attaching tags that are
% localized by beacons. The emerging localization technologies and low
% power tags will be key to MR interaction with devices. We could also
% potentially use visible light-based localization using overhead LED
% lights since AR devices have cameras. I want to develop design
% principles for fusing these sources of information at the
% low-level. To associate virtual content with physical objects, we have
% to identify them uniquely. While this can be done by adding visual
% markers to objects, this is not desirable. I want to explore tag-less
% localization using ambient signals, either based on light or
% wireless. As a first step towards interacting with objects in the
% environment, I am collaborating on a project to discover AR content on
% devices tagged with LEDs. 
% In addition to localization, other
% challenges in MR that I am interested in solving are managing the infrastructure that supports
% interaction, managing the virtual content associated with physical
% objects, and real-time updates to virtual content through physical
% interfaces.

 %is challenging interaction has the properties and challenges of CPS. 
 %Many of these system are not designed for detecting attack Often the signal models assumed do not
%Since the real-world signals are hard 
%Often, these systems are not designed to dthe signal models assumed by these systems do not account for attack models. 

\paragraph{Security}
% Cyber-physical systems are prone to attacks on the physical layer via
% access to the environment where the devices are located.  Since the
% real-world signals are noisy, the estimation algorithms allow for
% outliers and noisy measurements. The signal models assumed often don't
% account for attacks. This makes it hard to detect attacks at the
% physical layer. I am interested in understanding how we can integrate
% data from physically distributed devices and from multiple sources of
% information to make these systems more robust to attacks. As a start
% in this direction, I began to analyze this problem space for
% range-based localization, with Prof. Sdrjan Capkun's group at ETH
% Zurich. One attack model that range-based systems are susceptible to
% at the physical layer is distance enlargement attack. Some questions I
% am pursuing are - how would the beacon placement in a building change
% if we have to guarantee robustness against these attacks; can we use
% consistency between various sensors such as inertial, magnetic, floor
% plans and beacon measurements to detect attacks? Another question is -
% how does the device discovery and MAC layer change based on security
% properties of the physical layer?


Cyber-physical systems are prone to attacks on the physical layer via
access to the environment where the devices are located.  The challenge in detecting attacks at the physical layer signals is that %Since the
%real-world signals are noisy, 
the estimation algorithms allow for
outliers and noisy measurements and the signal models assumed often don't
account for attacks. 
%This makes it hard to detect attacks at the
%physical layer. 
I am interested in understanding how we can integrate
data from physically distributed devices and from multiple sources of
information to make these systems more robust to attacks. As a start
in this direction, I began to analyze this problem space for
range-based localization, with Prof. Sdrjan Capkun's group at ETH
Zurich. 
%One attack model that range-based systems are susceptible to
%at the physical layer is distance enlargement attack. 
Some questions I
am pursuing are - how would the beacon placement in a building change
if we have to guarantee robustness against distance enlargement attacks; can we use
consistency between various sensors and beacon measurements to detect attacks? 
how does the device discovery and MAC layer change based on security
properties of the physical layer? More broadly, I want to draw on my experience of experimentally
working with, and modeling, physical systems to think systematically
about re-designing system models and the estimation algorithms for
making these systems robust to attacks. %We require
%application-specific models as well as across-the-stack approaches for
%making systems secure to physical layer attacks.

%For emerging systems, I want to add 

\paragraph{Next-generation communication}
I am interested in using localization for solving challenges in next generation communication technologies and in exploring the problems that emerge when we consider the joint design of communication and localization. Location information will play a key role in fifth generation (5G) wireless networks - in resource allocation by predicting slow-varying channel characteristics and connectivity, and in dynamic spectrum management and routing. 
%Location plays a key role in emerging communication technologies such as mmWave as part of 5G. 
For mmWave technology physically distributed location-aware devices would coordinate together for beamforming, and for creating large MIMO arrays. %These rely on accurate location. %We can create reconfigurable arrays with mobile communication agents that can be accurately localized. 
Location-awareness can also enable better use of the spectrum by sensing the location of users, and by creating reconfigurable arrays with mobile agents. 
% in harsh environments. 
Location-aware wireless with next generation systems can enable new services for low-power distributed tags, such as those used for asset tracking. % or as aprt of IoT infrastructure. % devices. % and tags to truly become perpetual new applications for low-power tags. 
For instance wireless energy harvesting localizable tags can be charged by a configuration of drones flying through the space by directing energy at the tags. %%Another application of a location-awareness and communication for an internet-of-things paradigm with low-power tags that are powered by wireless energy-harvesting - is chanrign these end devices with diretional antennas. %that  wireless layer is future IoT devices that harvest energy from directional wireless sources. 
%Imagine a configuration of drones flying in the shortest path through a warehouse while wirelessly charging static or mobile tags with directional beams. 
I am also interested in using mmWave and future wireless for simultaneous localization and mapping. 
When localization and communication services mutually co-exist on a device, several design challenges emerge. For instance, determining and quantifying the relationship between the geometry and the communication capacity, trading-off allocation of compute resource for location estimation or communication. To solve these problems, I can draw from my experience in localization, communication and my approach of working across layers of the system stack.  %One of the challenges that would be faced by reconfigurable mobile arrays is estimating the geometry of the array based on the environment. 
 %the r

% the design challenges will span both domains, for isntace, 
% for both localization and communication to reach their full potential, we 

% Rather than siloed approaches for localization adn communication, 

% Other problems are in using mmWave MIMO for localization and mapping.  
% the application can 
% Here, some of the design challenges are 

%I am interested in emergy communication applications with spatially distributed elements. For isenhancing emerging communication technologies 

\paragraph{Real-time sensing of semantics}
Rather than using all low-level sensor data to make inference and then convert it to semantics, sense semantics direction based on application
\paragraph{Mobility..}
Mobility increases sensing. How to plan the mobility to maximize sensing input?
\paragraph{Something about closing the loop and control..}
%\subsection{Re-configurable communication infrastructure}
% \subsection{Human interaction with CPS}
% CPS systems that interact with humans are extremely challenging to design due to the unpredictability of humans, if they have to respond to the human. However, from a sensing perspective, if we can estimate the state of the human, we  %, and if the human is in the loop for controlling the system. 
% From a sensing perspective, the challenge is in estimating the state of the human in real time.  we can estimate the state of the human, we can a human in the loop can be the challenge is in estimating the  %With mobility of humans and the CPS components (such as drones), and with both being able to control, there are more challenges. To start with, I am
% Measuring human intent is hard. To start with, in systems with humas with phones, we can use the sensors on phone 

% A human CPS systems have to work reliably with a human-in-the-loop. A human-in-the-loop of an autonomous system introduces major challenges, especially in control. To start with, I am interested in understanding the implications of a mobile human-in-the-loop of a physically static CPS system.
%\subsection{Leveraging mobility and humans-in-the-loop}
%\subsection{Longer term research}
%In the longer term, I want to work in the broad areas  on 


%Learning to adapt resource allocation across a network}
%Often, any real-world physical networked system is asymmetric in terms of patterns across physical space. %For instance, in transport systems, there is an asymmetric distribution of traffic density across roads, and the roads are designed for catering to different traffic densities. 
%However, in sensor network and CPS design, the edge devices that are used for a function are all designed be identical. From a sensing point-of-view they all sense and communicate data at the same rate. As a result, nodes might be wasting resources (power, bandwidth), when they are not contributing to useful information. This resource allocation is often static. %For instance, In context of localization, some regions may have high node density and some lower. However 
%A common way in which this is addressed is by using low-power wakeup 
% \subsection{}

% %\textbf{Research problems}:
% %I enjoy identifying and working on fundamental research problems of practical relevance, then implementing and demonstrating my solutions. I work with industry and also take effort to understand the requirements of end users. For instance, 

%  % including energy metering, communication from lighting infrastructure to phones, and my dissertation is focused on indoor localization. 
% %\textbf{Energy metering: }Prior to joining CMU, I worked for two years in industry designing energy metering embedded products. Here, I worked on
% I designed a system and communication scheme for sending data from overhead LED lights to unmodified phones. This was one of the earliest systems in visible light communication (VLC) and light-based localization. This resulted in publications at IPSN 14 (cited 130+ times), VLCS 14 and demo-ed in IPSN 14. % and over the next four years the field has grown signifi in VLC-phone comm with multiple access and LED-based localization.  130 citations, field has grown.
% I have also contributed to other areas of CPS: time-synchronization (RTSS 14, RTAS 17) and electrical energy monitoring (ICCSP 13 + demo at ICCPS 13). My dissertation contributed to beacon-based indoor localization systems for mobile devices. This work has resulted in several publications (SenSys 15, RTAS 15, IPIN 16, IPSN 18 + demos in Sensys 15, IPSN 18), 2 patents, 2 time winning the international-level Microsoft Indoor Localization competition, 1 best demo, 1 startup, and has been funded by NSF, SRC, NIST, and industry. This work is being applied to indoor navigation, mobile persistent augmented reality, firefighter localization, asset mapping applications. 

% \section{Contribution to Indoor Localization}
% Infrastructure-based indoor localization and the focus of my thesis:
% Solve several problems.

% \subsection{ Convergence on a paradigm }
% Approach: range-based localization; ultrasonic compatible with phones; Apple; TI; 
% Impact is that I abstracted the technology to ranging. Tools and methods can generalize to a number of technologies.

% \subsection{Reduce the amount of infrastructure}
% Location acquisition in presence of NLOS
% (3)Integrate floor plan info.

% \subsection{Quantify the quality of placement}
% (2,4): Coverage; GDOP; algorithms; theoretical results.
% Insights about number of beacons, first systematic approach

% \subsection{Orientation acquisition}
% (1,3,4): characterized orientation, fusion, crowdsourced mapping

% \subsection{Mapping}
%  - sensor fusion

% \subsection{Next steps}
% Infrastructure-free ecosystem; IoT devices acting as beacons.


% \subsection{Applications} 
% Mobile AR, firefighter localization. Invited to museum conference, practical aspects - policy, who will pay for it, etc. 
% Reiterates that not enough to design systems that give high precision, they have to be practical. 

% \section{Future Work}
% %As next steps, I want to  future, I want to enable several location-based applications indoors, which I describe below. In the longer time, I want to work on CPS applications where the complexity of the physical processes poses challenges.
% \subsection{A scalable ecosystem for localization}
% There are still several problems to be solved in localization before it becomes an everyday reality. First, localization needs to be secure. 
% My vision - Asset tracking

% \subsection{Emerging applications}
% Augmented reality (AR) is exciting and has applications in several domains such as healthcare, manufacturing, entertainment and training. Location information is fundamental to AR. State-of-art AR devices use vision and inertial sensors to estimate the pose of the display device (headset or mobile device) with respect to the environment. However, this is not sufficient for several reasons. Vision suffers in highly-dynamic or low-light environments. As a result, upon startup the user has to walk around or move some distance. Vision also suffers when it encounters identical looking visual features that are in different locations. I have shown how we can enhance mobile AR using beacons and magnetic field to improve the pose acquisition \cite{}. We could also potentially use visible light-based localization using overhead LED lights since AR devices have cameras. I want to develop design principles for fusing all these sources of information at the low-level. To associate virtual content with physical objects, we have to identify them uniquely. While this can be done by adding visual markers to objects, this is not desirable. I want to explore tag-less localization using ambient signals, either based on light or wireless. As a first step towards interacting with objects in the environment, I am collaborating on a project to discover AR content on devices tagged with LEDs. In addition to accurate location, AR applications pose tight timing requirements due to human perception in the loop. 

% \subsection{Secure sensing}
% In addition to attacks on the cyber layer, these systems are prone to attacks on the physical layer via access to the environment where the devices are located. %Many of these system are not designed for detecting attack Often the signal models assumed do not
% %Since the real-world signals are hard 
% %Often, these systems are not designed to dthe signal models assumed by these systems do not account for attack models. 
%  At the physical layer, the challenge is that the real-world signals are noisy and the estimation algorithms allow for outliers and noisy measurements. The signal models assumed often don't account for attacks. I am interested in understanding how we can integrate data from physically distributed devices and from multiple sources of information to make these systems more robust to attacks. As a start in this direction, I began to analyze this problem space for range-based localization, with Prof. Sdrjan Capkun's group at ETH Zurich. One attack model is that a compromized device reports an enlarged distance measurement to a beacon. For this attack model, we could tackle this in two ways. First, we can deploy beacons in a certain manner and check for consistency across beacons. Second, we can check for consistency between different sensors such as inertial sensors, magnetic sensors, floor plan and beacon measurements. We require application-specific models for making systems secure at the physical layer.%For emerging systems, I want to add 

 
% \subsection{Reconfigurable infrastructure}
% Large-scale problems in the real-world rely on various infrastructure. We require    


% \subsection{Leveraging mobility }
% Mobile agents, automated (robots, drones, mobile devices) or humans introduce dynamics.   

% Ultimately the goal of these systems is to enable applications that are useful to humans in some way.
% A human in the loop of a CPS system poses new challenges with respect to prediction and estimation, but introduces new ways to improve performance using control and action by the human. In context of localization and mapping, the first step in this direction I want to explore is human-in-the-loop beacon mapping. Can we guide the user to walk towards a certain region or walk in a certain direction to improve the mapping accuracy with reduced time-to-estimate? A related problem is can the user move the mobile device in a certain manner to reduce the time taken to discover beacons as well as the time to acquire location and orientation with improved accuracy? The idea is that mobility increases sensory input. In the longer term, I am interested in exploring problems that arise when humans interact with CPS in applications such as mixed reality for training. Here the challenge is that the performance of the CPS has to meet the human perception requirements, and the CPS has to be robust to the unpredictability of humans. 

% \subsection{Other CPS applications}
% Most scalable CPS applications face the problem of managing infrastructure and deployment. Further, 




% %  systems  tp well understood models, we can apply theoretical tools from state estimation, signal pricessing, optimzation
% % On the practical side, 

% % While on one hand, system implementations are tuned to a certain deployment or to the devices . My goal is to bring a systematic approach to the design of large-scale 
% % in a systematic manner that work in the real-world. 

% \newpage
% I am intereteed in designing cyber-physical systems (CPS) in a principled manner for the real world. CPS enable new and exciting applications such as interactive experiences with mixed reality, smart and responsive infrastructure, autonomous vehicles, swarm robotics, and computing to improve healthcare. These systems have physically distributed networked sensors and actuators (cyber systems) with the goal of monitoring and changing the state of physical systems. The design of CPS is hard due to the complexity, spatially-varying and time-varying nature of physical systems. %Hence it hard to accurately model the physical systems. 
% Further, the cyber system has to conform to the real-time nature of the physical system it is interacting with. Due to these challenges, there are two common approaches to CPS design. The first abstracts away the hard-to-model nuisance properties of the physical system, and offers systematic analysis of the system, but is far from practical. The second approach is to implement customized cyber systems that are practical and perform well under some environments or assumptions, but these system implementations are far from offering systematic analysis and don't scale across different physical environments. \\

% I design practical systems in a systematic manner by bridging these two approaches. I work across the CPS stack and develop an understanding of the end-end system: physical system, embedded system, sensing, communication, estimation. I jointly design the estimation algorithms and system models, and the physical networked embedded system. I do this in the following manner: First, I understand the interaction between the cyber and physical system - what sensors can be used, what signals can be measured, what is the system we are trying to estimate or control, what parameters affect the system. Then I understand the system design constraints - bandwidth, sensor update rate, timing requirements, physical resources. Next, I build models for the cyber-physical interaction that are general enough for us to apply theoretical tools but practical in the real world. These include system models and sensor models. To develop these, I experiment and deploy systems, and understand the theoretical tools relevant to the estimation problem. Finally, I jointly design the cyber system (where to place sensors, what sensors we collect data from, scheduling the devices) and the estimation algorithms.\\

% I now explain my approach with examples in indoor localization, the focus of my dissertation. 

% \textbf{Impact in CPS}:\\



% %First, I anlayze the interaction between the cyber and physical system through experements and a first-principles . I then
% %The specific solutions are dependent on the CPS application. 
%  %jointly design system models and estimation algorithms with networked embedded systems.
% %building tools, models, algorithms and systems that work in the real-world and have underlying principles that can generalize. I do this by 



% \newpage

% I am interested in a enabling new cyber-physical system (CPS) applications. Exciting CPS applications includes interactive experiences with mixed reality, smart and responsive infrastructure, autonomous vehicles, swarm robotics, and computing to improve healthcare.

% CPS have physically distributed networked sensors and actuators with the goal of monitoring and changing the state of the physical world. Realizing these systems in practice in a reliable manner is hard for several reasons. First, the real-time nature of physical world poses timing constraints on the estimation and control. Second, the physical systems have spatially-varying properties, that are difficult to model and estimation has to be performed jointly by distributed embedded devices. Third, the properties of the system vary with deployment and environment, making it hard to create models that generalize. As a result, CPS design either does not scale in terms of resources used, make assumptions that hold only in some environments or don't meet the performance demanded by these emerging applications.\\
% % Focus on limited performance metrics.

% %faces the conflicting objectives to  To realize these emerging applications, we require scalable systems with high peformance in any environment.\\
% \textbf{My approach:}\\
% I approach CPS challenges from a sensing and estimation point-of-view. My goal is to achieve (1) high performance, ie quality of information inferred (accuracy, reliability, timing of estimating the state of system) (2) with low resources, ie the physical infrastructure and prior information required (environment-specific, device-specific calibration). %My goal is to increase information inferred and reduce the resources used.\\
% %I approach CPS design from estimation and sensing point-of-view, with understanding of end-end system.
% The questions that guide my research are:\\
% (1) How to use sensors in a smarter way? - more data with limited resources\\
% (2) How to quantify the information available as a function of resources? - this can inform us on the resources required\\
% (3) How to intelligently integrate data from different sources? - more inference from same data using better algorithms\\
% (4) What is the underlying system model?

% %System constraints that are practical: resources.
% I work at the interface of signals and systems. To develop my solutions - I understand end-end system components including communication, networking, embedded hardware, sensing, control and timing; I apply tools from estimation, statistical signal processing, optimzation to embedded sensing systems. I build and deploy my solutions in the real-world. \\ 

% \textbf{Impact in CPS}:\\
% I designed a system and communication scheme for sending data from overhead LED lights to unmodified phones. This was one of the earliest systems in visible light communication (VLC) and light-based localization. This resulted in publications at IPSN 14 (cited 130+ times), VLCS 14 and demo-ed in IPSN 14. % and over the next four years the field has grown signifi in VLC-phone comm with multiple access and LED-based localization.  130 citations, field has grown.
% I have also contributed to other areas of CPS: time-synchronization (RTSS 14, RTAS 17) and electrical energy monitoring (ICCSP 13 + demo at ICCPS 13). My dissertation contributed to beacon-based indoor localization systems for mobile devices. This work has resulted in several publictions (SenSys 15, RTAS 15, IPIN 16, IPSN 18 + demos in Sensys 15, IPSN 18), 2 patents, 2 time winning the international-level Microsoft Indoor Localization competition, 1 best demo, 1 startup, and has been funded by NSF, SRC, NIST, and industry. This work is being applied to indoor navigation, mobile persistent augmented reality, firefighter localization, asset mapping applications. 

% \section{Contribution to Indoor Localization}
% Infrastructure-based indoor localization and the focus of my thesis:
% Solve several problems.

% \subsection{ Convergence on a paradigm }
% Approach: range-based localization; ultrasonic compatible with phones; Apple; TI; 
% Impact is that I abstracted the technology to ranging. Tools and methods can generalize to a number of technologies.

% \subsection{Reduce the amount of infrastructure}
% Location acquisition in presence of NLOS
% (3)Integrate floor plan info.

% \subsection{Quantify the quality of placement}
% (2,4): Coverage; GDOP; algorithms; theoretical results.
% Insights about number of beacons, first systematic approach

% \subsection{Orientation acquisition}
% (1,3,4): characterized orientation, fusion, crowdsourced mapping

% \subsection{Mapping}
%  - sensor fusion

% \subsection{Next steps}
% Infrastructure-free ecosystem; IoT devices acting as beacons.


% \subsection{Applications} 
% Mobile AR, firefighter localization. Invited to museum conference, practical aspects - policy, who will pay for it, etc. 
% Reiterates that not enough to design systems that give high precision, they have to be practical. 

% \section{Future Work}
% %As next steps, I want to  future, I want to enable several location-based applications indoors, which I describe below. In the longer time, I want to work on CPS applications where the complexity of the physical processes poses challenges.
% \subsection{A scalable ecosystem for localization}
% There are still several problems to be solved in localization before it becomes an everyday reality. First, localization needs to be secure. 
% My vision - Asset tracking

% \subsection{Emerging applications}
% Augmented reality (AR) is exciting and has applications in several domains such as healthcare, manufacturing, entertainment and training. Location information is fundamental to AR. State-of-art AR devices use vision and inertial sensors to estimate the pose of the display device (headset or mobile device) with respect to the environment. However, this is not sufficient for several reasons. Vision suffers in highly-dynamic or low-light environments. As a result, upon startup the user has to walk around or move some distance. Vision also suffers when it encounters identical looking visual features that are in different locations. I have shown how we can enhance mobile AR using beacons and magnetic field to improve the pose acquisition \cite{}. We could also potentially use visible light-based localization using overhead LED lights since AR devices have cameras. I want to develop design principles for fusing all these sources of information at the low-level. To associate virtual content with physical objects, we have to identify them uniquely. While this can be done by adding visual markers to objects, this is not desirable. I want to explore tag-less localization using ambient signals, either based on light or wireless. As a first step towards interacting with objects in the environment, I am collaborating on a project to discover AR content on devices tagged with LEDs. In addition to accurate location, AR applications pose tight timing requirements due to human perception in the loop. 

% \subsection{Secure sensing}
% In addition to attacks on the cyber layer, these systems are prone to attacks on the physical layer via access to the environment where the devices are located. %Many of these system are not designed for detecting attack Often the signal models assumed do not
% %Since the real-world signals are hard 
% %Often, these systems are not designed to dthe signal models assumed by these systems do not account for attack models. 
%  At the physical layer, the challenge is that the real-world signals are noisy and the estimation algorithms allow for outliers and noisy measurements. The signal models assumed often don't account for attacks. I am interested in understanding how we can integrate data from physically distributed devices and from multiple sources of information to make these systems more robust to attacks. As a start in this direction, I began to analyze this problem space for range-based localization, with Prof. Sdrjan Capkun's group at ETH Zurich. One attack model is that a compromized device reports an enlarged distance measurement to a beacon. For this attack model, we could tackle this in two ways. First, we can deploy beacons in a certain manner and check for consistency across beacons. Second, we can check for consistency between different sensors such as inertial sensors, magnetic sensors, floor plan and beacon measurements. We require application-specific models for making systems secure at the physical layer.%For emerging systems, I want to add 

 
% \subsection{Reconfigurable infrastructure}
% Large-scale problems in the real-world rely on various infrastructure. We require    


% \subsection{Leveraging mobility }
% Mobile agents, automated (robots, drones, mobile devices) or humans introduce dynamics.   

% Ultimately the goal of these systems is to enable applications that are useful to humans in some way.
% A human in the loop of a CPS system poses new challenges with respect to prediction and estimation, but introduces new ways to improve performance using control and action by the human. In context of localization and mapping, the first step in this direction I want to explore is human-in-the-loop beacon mapping. Can we guide the user to walk towards a certain region or walk in a certain direction to improve the mapping accuracy with reduced time-to-estimate? A related problem is can the user move the mobile device in a certain manner to reduce the time taken to discover beacons as well as the time to acquire location and orientation with improved accuracy? The idea is that mobility increases sensory input. In the longer term, I am interested in exploring problems that arise when humans interact with CPS in applications such as mixed reality for training. Here the challenge is that the performance of the CPS has to meet the human perception requirements, and the CPS has to be robust to the unpredictability of humans. 

% \subsection{Other CPS applications}
% Most scalable CPS applications face the problem of managing infrastructure and deployment. Further, 

% %we require approaches that are both robust to attacks and work despite the 
% %More broadly I interested in including security the co-design of estimation algorithms and  
% %Another challenge in an ecosystem with hetergoeneous untrusted devices is secure device discovery. How 


% Beyond the physical layer, the medium access layer in a he
% I am also interested in location and proximity-based authentication 

% The challenge is detecting attacks on the physical layer is that 

% Attacks on the physical layer are hard to detect if 

% . Attacks on the physical layer are a possible when the attacker has access to the environment where the end-point devices are located.

%  based on access to the physical environemnt
%  an attacker has access to the physical environment, the system is 

% Detecting attacks at the physical layer are hard for several reasons. First

% Of these, attacks at the physical layer where the signal is modified (by spoofing or device being compromised)



% \subsection{Information processing at edge}
% With large amount of sensor data, and timing requirements + power requirements on devices + shared communication spectrum, can we design sensor fusion approaches with local processing. Challenge is in making the decision on when to compute locally vs when to share the information. 
% Problem: edge devices have sensors.
% communication is expensive and consumes power. Can we design ways


% \subsection{Secure sensing}
% Security affects all layers of system stack.\\
% Attack at physical layer  - of interest to me\\
% Hard because - system models assumed do not account for attack models.\\
% Potential apprpach - using other sensing sources.\\
% Preliminary work - ETH zurich, secure localization.


% \subsection{Other CPS applications}



% \subsection{Semantic representation of information}
% Future CPS systems - context is important. \\

% Representation of information.





% \newpage
% %Ultimately, there is a trade-off between performance 
% %As a result, the solutions are either not scalable in terms of resources used, or make assumptions 


% % CPS design is challenging due to the real-time propoerties,

% % Real-time nature : timing constraints on estimation
% % Physically distributed: makes it hard to model the input, output
% % Systems are deployed in different environment: makes it hard for systematic approach.



% % Estimation with high performance (accuracy, timing properties, reliability) and low resources (infrastructure deployed, and any environment-specific calibration or setup)

% % As a result, solutions:
% % Impractical in terms of resources used, do not scale.
% % Make assumptions that hold only in some environments.
% % Focus on limited performance metrics.






% % What I am interested in

% %I am interested in solving problems that emerge when we integrate cyber-physical systems (CPS)  
% %I am interested in solving problems that emerge when physical systems in the real-world are integrated with physically distributed computing systems over a network. 
% %Cyber-Physical Systems (CPS) is the paradigm 
% I am interested in a principled approach for sensing and estimation in cyber-physical systems (CPS) in the real-world. Some examples of CPS applications are smart grids, internet-of-things, swarm robotics, smart infrastructure.
% %CPS are systems where computing is integrated with the physical world through physically distributed sensors and actuators over a network. The goal of this integration is to monitor and change the state of the physical world.  
% CPS refers to physically distributed networked embedded systems integrated with the physical real-world through sensors and actuators. The goal of this integration is to monitor and change the state of the physical world. 

% Every CPS application has a system solution. The real challenge is in designing solutions that navigate the trade-off between performance and resources in a systematic manner and work in the real-world at scale. %The ch  %We care about two aspects - performance and resources. 
% The performance of the embedded system we design is characterized by the accuracy, timing and reliability of the estimating and controlling the physical system. The resources are characterized by density and cost of devices, power consumed by devices, and time/effort invested in deploying or calibrating the system. My goal as a system designer is to achieve high performance with low resources. %Every CPS application has a system solution. The challenge is in designing solutions that navigate the trade-off between performance and resources in a systematic manner and work in the real-world at scale.
% %These are systems where computing is integrated with the physical world through  physically distributed sensors and actuators over a network. The goal of this integration is to monitor and change the state of the physical world.  

% %They rely on a model of the system.
% %Advancements in low-power microcontrollers, radios, sensors, devices, communication and network technologies are now pushing CPS to a point where .\\
 

% %Why is this hard? Large-scale real-world physical systems are complex, have temporal dynamics, and vary with environmental parameters that are difficult to characterize. 
% %Hence, they are difficult to model in a systematic approach.
% %The performance of the embedded system we design is characterized by the accuracy, timing and predicatiability of estimating and controling the physical system.
% %Our goal is to achieve 
% %Hence, they are difficult to model in a systematic approach.  % that are hard to , and as a result are difficult to model. 
% %This makes it hard to design systems in a systematic manner to have reliable performance in the real-world. 
% %This makes it hard to design systems %There are several ways to design these systems. However, it is hard to the real challenge is to design systems that can achieve reliable performance in the real-world, with contraints This makes it hard to design computing systems that achieve reliable performance at scale. 
% %Performance depends on the application, and is measured by - accuracy, timing, predictability of estimating and controling the physical system.  A common approach to design systems to meet the performance requirement in the real-world is to use more resources - such as higher density or more expensive sensors. Another approach is to customize the system, such as performing environment-specific calibration to compensate for an unknown or low fidelity model of the system. 
% %Every CPS application has \txtit{a} solution but the real challenge is in navigating the design space with trade-off in performance and amount of resources used. The first step to navigating this trade-off is that we need a systematic approach to quantify 
% % My research aims to design approaches for CPS that are systematic
% %My research understands this trade-off between performance and resources to design systems 

% I work at the interface of signals and systems - both physical systems and embedded systems. 
% %My work addresses this challenge through a sensing and estimation approach. I work at the interface of signals and systems - both physical systems and embedded systems. 
% % I work at the intersection of theory and practice and 
% %I develop abstractions that are general enough to apply principled approaches, and practical in the real-world.  
% My goal is to do the best with the available sensors and resources, by (1) opportunistic use of sensors (2) designing better system models and (3) designing new estimation algorithms. I develop these through experiments and an understanding of signals and systems from first principles. %With systems, I refer to physical systems as well as embedded systems. 
% % physical systems or 
% More broadly, I apply tools from estimation, signal processing and optimization to embedded sensing systems. I implement and evaluate my approaches by deploying systems in the real-world. \\

% \textbf{Overview of my research in indoor localization:}\\
% %Location and time are key properties of the physical world. 
% %My dissertation focuses on indoor localization - an instance of a CPS problem, and a fundamental property for several CPS applications. 
% My dissertation focuses on indoor localization - a classic instance of a CPS problem, with physically distributed devices, real-time properties, networked components, embedded and mobile devices. Location is also a fundamental property for several CPS applications. 
% %Localization tighly couples computing with the physical world.  
% %with tight coupling between computing and the physical world. Location is a fundamental property for CPS applications. 
% There are more than a million papers on the topic of indoor positioning and indoor localization. Yet localizing mobile devices inside buildings isn't an everyday reality. A systematic scalable approach to indoor localization that can navigate the trade-off between performance and resources is hard due to: (1) complexity of indoor environments (2) temporal dynamics due to people, devices and things moving (3) each environment is unique and varied. %As a result it is hard to model the interaction of signals with indoor spaces. This makes it hard to design system solutions that can navigate the trade-off between performance and resources. %Ideally, we want a system that is accurate all the time. 
% Performance in indoor localization is characterized by accuracy, acquisition time (time to initialize), and the update rate. The resources are characterized by amount of infrastructure deployed, additional hardware on the thing/person/device being localized, and the effort and time to calibrate, map or setup the system.  \\%Existing solutions for mobile localization are of two types. 
% %Localization app
% Let us consider the various localization solutions for mobile devices. Infrastructure-free approaches use sensors on mobiles (inertial, magnetic, camera), signals from WiFi Access Points in the environment, and floor plan information. These systems require environment-specific and device-specific calibration. Infrastructure-based systems are capable of accurate positioning but they deploy beacons and require these beacons to be setup and mapped. Most importantly, unless there is a high density of beacons, both approaches often require the person to move some distance before the accuracy is acceptable, resulting in high acquisition time. No existing solution is accurate, instant, updates continuously, has zero-cost, is compatible with commodity devices and most importantly, works reliably at scale in the real-world. \\

% %My dissertation builds upon 
% %My approach to indoor loclaization is to  

% %Across existing literature in localization, accuracy is achieved by 
% %difficulty in modeling systems complexity of indoor spaces design trade-offs between performance and cost; requirin Some 

% %My vision for an indoor localization ecosystem of the future is that devices . Is this vision possible? 
% %My work addresses these challenges, towards the vision of an infrastructure-free opportunistic indoor localization ecosystem that can accurately and instantly locate things, devices and people.\\
% My vision for indoor localization is  an infrastructure-free opportunistic indoor localization ecosystem that can accurately and instantly locate things, devices and people. I envision that in future, IoT devices, smart appliances, WiFi access points, and mobile devices such as phones, tablets, laptops will have ranging (time-of-flight or time-difference-of-arrival) capabilities. The ranging would be based on current technologies (ultrasonic, ultra-wideband) or emerging technologies (BLE5, 802.15.4z, WiFi 802.11mc, mmWave). These devices when stationary will act as beacons to localize mobile devices. %Developments in academia, industry and standards are pushing ranging technologies into commodity devices. Current ranging technologies include ultrasonic ranging, ultra-wideband ranging and BLE ranging. Emerging standards such as BLE5, 802.15.4z, WiFi 802.11mc are pushing ranging capabilities into commodity devices. \\


% My dissertation takes steps towards this vision by solving three problems faced by beacon-based ranging systems in the real-world. First, there is no systematic approach to quantify the quality of a beacon configuration. 
% %Given a limited number of beacons, where to place them indoors? 
% My first contribution is a new abstraction of floor plans and beacon ranging which (1) reduces the number of beacons required as compared to state-of-art, (2) proposes a new metric that quantifies the quality of a beacon placement (3) proposes algorithms for beacon placement \cite{rajagopal2016beacon}. An important practical problem faced by range-based systems is accurate location acquisition in the presence of non-line-of-sight signals and few line-of-sight signals. My second contribution is a localization solver that leverages the floor plan geometry to acquire accurate location, in the presence of non-line-of-sight signals and low line-of-sight beacon density \cite{rajagopal2018enhancing}. Though most of the current systems focus on location, an important requirement for applications such as navigation and augmented reality is knowing the device orientation as well. My third contribution is a novel orientation acquisition approach, using beacons and magnetic field sensing \cite{mobileAR}. In addition, I have designed algorithms for tracking \cite{lazik2015alps}, beacon mapping \cite{lazik2015alps,mobileAR} and reducing the number of beacon by enabling ToF ranging from TDoA ranging \cite{rtas-alps-platform}\\

% %To achieve my vision for indoor localization, 
% I contribute to fundamental research, implement and deploy systems and collaborate with external organizations. \\%will continue to work with industry and standards organizations, in addition to contributing to fundamental research. I implement and deploy systems in the real-world.\\
% \textbf{Demos:} I have demonstrated my solutions with an ultrasonic beacon platform that localizes unmodified phones \cite{lazik2015alps, lazik2015alpsdemo, rtas-alps-platform}. 
% I implemented an early version of the floor-plan aware solver  \cite{rajagopal2018enhancing} in our system that won the Microsoft Indoor Localization Competition in 2015. Our orientation acquisition technique applied to mobile augmented reality won best demo at IPSN 2018 \cite{rajagopal2018welcome}. Our localization algorithm designed for accurate tracking \cite{mobileAR} won the Microsoft Indoor Localization Competition in 2018 with Ultra-Wideband beacons.\\
% \textbf{Industry:} Our ultrasonic localization platform is spun out into a start-up. We have demonstrated mobile augmented reality applications with this system. I worked with Apple at a summer internship on one of their earliest prototypes of WiFi ToF localization, which eventually resulted in product impact. I am currently working with Texas Instruments on BLE ToF and implementing localization and SLAM on BLE. \\
% \textbf{Standards:} I am working with National Institute of Standards and Technologies on firefighter localization in emergency scenarios. We are working on an infrastructure-free localization paradigm I believe that for any infrastructure to become part of buildings (such as fire sprinklers or exit signs), standards enforced for safety can be a key enabler. We are exploring the possibility of the exit signs as locations for low-power beacons to be deployed in emergency scenarios.\\



% % I demonstrate my approaches by implementing them and deploying systems. Our ultrasonic-based localization system  \\
% % \cite{rajagopal2016beacon}\\
% % \cite{rajagopal2018enhancing}\\
% % \cite{lazik2015alps}\\
% % \cite{lazik2015alpsdemo} : demo\\
% % \cite{} : AR demo

% %Time-of-flight ranging 
% %My dissertation addresses important challenges towards this vision, in a principled manner.  
% %Range-based 
% %I take an alternate My disseration takes an alternative approach. I 
% %ToF-based localization accuracy is 
% % quantifiable precisely by the time-bandwidth product of the ranging channel, and the relative location of infrastructure with respect to the . The accuracy of positioning is limited by the ranging accuracy and the relative location of beacons. There are engineering challenges for why ToF ranging is not part of commodity devices. But there are emerging standards for ToF ranging 
% % ToF-based localization accuracy is quantified precisely. %are capable of accurate positioning. The limits can be quantified precisely. 

% % Indoor localization as a problem space requires wo
% % emerging ToF technologies - envision future ecosystem.\\
% % Contributions span fundmantal and applied.\\
% % On fundamental - no systematic approach - IPIN, computational geometry
% % IPSN
% % Orientation
% % SLAM
% % Ultrasonic localization - cite papers, demo - startup - won competition.\\
% % Most precise phone-based localization system.\\
% % RF - Apple - earliest prorotype.\\
% % TI - BLE SLAM
% % UWB - NIST, won competition.\\


% \section{Indoor Localization}
% I now describe in detail my main contributions to indoor localization. %I have adopted an opportunistic sensor-fusion approach.\\

% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % The first challenge for localization is that it has to support heterogeneous devices with varied sensing capabilities. My approach to this is to
% % %I believe that to enable indoor localization to become a reality, 
% %  embrace the emerging ranging and localization technologies that are finding their way into newer standards and mobile devices, and build an ecosystem that enables these technologies to scale up and be integrated with heterogeneous sensors. \textit{talk about range-based localization systems and envisioned ecosystem. }.\\%solve the problems that these systems face which scaling up. My world adopts a sensor fusion approach 
% % %My approach: range-based localization\\

% The first problem is that there is no systematic understanding of how and where to place range-based beacons. Currently, beacon placement is done empirically by domain-experts, and indoor spaces are over-provisioned with beacons. When deploying beacons, an installer faces the conflicting objectives of reducing the number of beacons to be placed and increasing system coverage, accuracy and resilience. Existing approaches for trilateration require three or more beacons to determine a unique position solution. First, we show that with prior knowledge of the map and a model of beacon coverage, it is possible to uniquely localize with only two beacons. This not only reduces installation cost by requiring fewer nodes, but can also improve robustness. One of the main challenges with respect to beacon placement algorithms is defining a metric for estimating performance. We propose augmenting the commonly used Geometric Dilution of Precision (GDOP) metric to account for indoor spaces, and define a new metric - Indoor GDOP. We adopt the GDOP since the Cramer Rao Lower bound on the variance of the location estimate is proportional to the GDOP and the ranging error, under the assumption that the ranging noise is additive white noise Gaussian. We then use this indoor GDOP metric and propose new beacon placement algorithms that optimize for  coverage and expected accuracy. We designed a toolchain for the beacon placement algorithms on floor plans. When applied to a set of real floor plans, our placement algorithms are able to reduce the number of beacons between 22\% and 60\% (33\% on an average) as compared to standard trilateration. I further extended this work in collaboration with Prof. Jie Gao from Stony Brook and her student. We mathematically formulated the beacon placement algorithm and proposed placement algorithms with provable guarantees \cite{beaconplacementtheory}. I believe that such systematic approches and automated tools for beacon placement are necessary while scaling up these systems from labs to building-scale. \\


% The second problem is that in reality, signals from line-of-sight beacons get blocked, we also receive incorrect non-line-of-sight (NLOS) signals. To maintain accuracy despite these, either beacons are over-provisioned (trading-off cost) or other sensor measurements are used over time, or the user is asked to walk around (trading-off time-to-estimate). Hence, none of the existing approaches can acquire location with low beacon density. To solve this problem, I design a new floor-plan aware location estimation technique that can instantly acquire location  
% %Our second contribution is a localization algorithm that is able to instantly acquire location 
% in the presence of low-beacon density and incorrect non-line-of-sight (NLOS) signals. 
% %To get accurate location in the presence of non-line-of-signals, existing approaches either deploy beacons with high-density (increasing cost) or use inertial-tracking to converge on an estimate over time (increasing time-to-first-fix). 
% This solving approach uses the floor plan information and can disambiguate multiple feasible locations taking into account a mix of LOS and NLOS hypotheses to accurately localize instantly with significantly fewer beacons. We demonstrate our geometry-aware solving approach using a new ultrasonic beacon platform that is able to perform direct time-of-flight ranges on commodity smartphones. The platform uses Bluetooth Low Energy (BLE) for time synchronization and ultrasound for measuring propagation distance. When evaluated in multiple real deployments, our approach was able to improve the 80\% localization accuracy from 4-8m to 1m in low-beacon density and NLOS conditions. We are able to detect and remove NLOS signals with 91.5\% accuracy.\\

% The third problem I addressed was orientation acquisition on mobile devices. While beacons can provide accurate localization, orientation acquisition is still a challenge. Orientation is necessary for applications such as mobile augmented reality. Most existing systems estimate the orientation by requiring the user to walk around for some distance, or relying on visual features in the environment.  %that is required for mobile Augmented Reality still remains a challenge. 
% We show how the combination of Visual Inertial Odometry and beacons can be used to crowd-source a dense magnetic field map. Future users can use this map at startup to calibrate their compass in order to instantly estimate orientation. We show in a demonstration system running on an iPhone that can acquire location with 80\% percentile 3D accuracy of 24cm. We also see that our magnetic field mapping approach can instantly estimate orientation with 80\% percentile accuracy of 16 degrees.  We demonstrate an end-to-end system that automatically configures beacons, generates the magnetic field map and supports a mobile AR applications that works in any environment without requiring the sharing of large and often fragile point-cloud maps. \\

% Finally, I have designed algorithms for tracking \cite{lazik2015alps}, beacon mapping \cite{lazik2015alps,mobileAR} and reducing the number of beacon by enabling ToF ranging from TDoA ranging \cite{rtas-alps-platform}.\\

% %Applications such as augmented reality require the device's orientation in addition to location. 
% %Improving Mobile Augmented Reality Re-localization \\ using Beacons and Magnetic-field Maps

% %The third problem is that for many applications, we require to know the orientation of the device in addition to location. However, 
% %Our third contribution is to estimate instant orientation, in addition to location. 
% %typical approaches for orientation acquisition use the mobility of the device (trading-off time-to-estimate). I propose an approach where we can leverage the magnetic field along with the localization system to 
% %We use the location estimated from a beacon infrastructure along with a map of magnetic field direction to 
% %instantly estimate the device’s orientation immediately without requiring the user to walk around. Our system provides 90\% localization accuracy of 24cm with LOS beacons and 90\% orientation acquisition accuracy of 16° from magnetic field sensing. blah blah blah...\\
% %blah blah blah...\\
% %blah blah blah...\\
% %blah blah blah...\\
% %blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\


% %My approach to this is to abstract the floor plan and beacon ranges to models where we can apply concepts from estimation theory. Currently, beacon placement is done empirically by domain-experts, and indoor spaces are over-provisioned with beacons. Existing approaches require three or more beacons to determine a unique position solution. I show that with prior knowledge of the map and a model of beacon coverage, it is possible to uniquely localize with only two beacons. I introduce a metric to quantify the quality of a beacon placement and design an algorithm for systematically placing beacons in a floor plan. This is based on the Cramer Rao Lower bound on the location estimate, under the assumption that the ranging noise is additive white noise Gaussian. When applied to a set of real floor plans, this placement algorithm is able to reduce the number of beacons by 33\% on an average as compared to standard approaches. \\

% %we address the problem of range- based beacon placement given a floor plan to support indoor localization systems. Existing approaches for trilateration require three or more beacons to determine a unique position solution. We show that with prior knowledge of the map and a model of beacon coverage, it is possible to uniquely localize with only two beacons. This not only reduces installation cost by requiring fewer nodes, but can also improve robustness. One of the main challenges with respect to beacon placement algorithms is defining a metric for estimating performance. We propose augmenting the commonly used Geometric Dilution of Precision (GDOP) metric to account for indoor spaces. We then use this enhanced GDOP metric as part of a toolchain to compare various beacon placement algorithms in terms of coverage and expected accuracy. When applied to a set of real floor plans, our approach is able to reduce the number of beacons between 22% and 60% (33% on an average) as compared to standard trilateration.


% % The final problem - is mapping. We also present a pedestrian-aided automatic mapping approach for mapping the beacons and magnetic field rapidly upon setup... \\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\
% % blah blah blah...\\

% %In summary, there are several ways of solving the localization problem. However, the real challenge is in solving it in a manner that maintains performance (high accuracy, low time-to-estimate) in a manner that is also cost efficient (low infrastructure, mapping and setup effort). My work addresses these challenges in a principled manner by creating new models and estimation techniques. \\


% \section{My research in other areas in CPS}
% In addition to location, time is a fundamental property of CPS. I have worked on problems in time-synchronization \cite{buevich2013hardware, dongare2017pulsar, rtas-alps-platform}.  I have also worked on CPS applications of energy metering and visible light communication, using a sensing approach. The challenge across these applications is in system design that achieves performance with limited resources. \\
% %is in system design  I have worked on the challenges I have solved are to address the CPS design space with trade-off between performance and resources. \\
% %I have worked on problems in time-synchronization in CPS, and in CPS applications of energy metering and visible light communication.  
% \textbf{Energy metering}:\\
% Prior to joining CMU, I worked for two years in industry on designing embedded energy metering products. % that monitor aggregated energy from a group of houses/industries. 
% Though we can measure aggregated energy, it is hard to dis-aggregate individual appliances without using plug-in meters for each appliance. At CMU, I explored the problem of dis-aggregating individual appliances within a home. 
% To solve this, we proposed a solution with novel sensing, a simple model and an estimation algorithm. We designed contactless battery-operated electromagentic field (EMF) sensors that we deployed near each appliance. This sensor detected appliance state transitions based on magnetic and electric field fluctuations. We modeled each appliance as a two-state device and designed an algorithm for load-disaggegation using the data from magnetic field sensors and whole house energy meter \cite{rajagopal2013magnetic} and demonstrated the system \cite{rajagopal2013demo}. 
% %including reference energy meters used by utilities for calibrating individual meters, and multi-function transducers deployed in substations to monitor aggregated energy from a group of houses/industries. 
% %However, we did not have ways to monitor energy within homes at appliance-level. I explored this problem when I started at CMU. The challenge was in solving this problem to achieve high performance (accurate dis-aggregation of load) and use low resources (non-intrusive monitor appliances). 
% %detecting appliance state-transition using magnetic field and correlating the sensor information with whole house energy meter data to dis-aggregate individual appliances . 
% Working with energy metering and the electrical infrastructure of homes, a question that emerged was can we opportunistically use the power lines as a communication channel indoors? %Though there were standards for power line communication (PLC), the interesting question there was is it possible to design a communication scheme for PLC that could use the WiFi communication stack? 
% To explore this question, I interned at Texas Instruments Communications and Systems Lab and designed a power line communication-WiFi hybrid communication scheme in simulation at the MAC and PHY layer.\\

% \textbf{Visible Light Communication}:\\ 

% The next question that emerged was, even if the PLC could be used as a backbone infrastructure, how can we communicate data from the electrical infrastructure to mobile devices? This question was timely, as back in 2013, LED lights were starting to phase out incandescent lights, and it was clear that LED lights will become pervasive in the future indoor infrastructure. LED lights turn on and off at a high frequency. 
% %I then explored the question - can we opportunistically use the lighting infrastructure indoors to send data to phones? 
% %The question we asked is - can we use light as a medium and modulate the signals on LED lights to send data, and sense this data from phones? 
% %The motivating application for this was to coarsely localize phones indoors based on which lights are in proximity, and to leverage lights as a new communication infrastructure indoors. 
% The challenge was that for the lights to be flicker-free, they have to be modulated at a frequency much higher than the camera frame rate. To communicate data despite this limitation, I designed a novel sensing approach that exploited the rolling-shutter effect of cameras on phones to detect a high frequency light signal. I extended this to a modulations scheme that supported multiple lights. The main challenge was in maintaining performance when the user holds the phone normally, rather than pointing at the light. To overcome this, I modeled the exposure and focus control of the camera as filters that respond differently to the light signal and the scene captured and used this to improve the signal-to-noise ratio. This system was one of the earliest systems to show that we can send data from overhead LED lights to phones using the rolling shutter effect \cite{rajagopal2014visual}.  We demonstrated this system \cite{rajagopal2014demonstration} and also extended the work \cite{rajagopal2014hybrid} by designing a hybrid communication scheme where a single light transmits two independent data streams on a single channel using a combination of modulating the duty cycle and frequency, to communicate simultaneously to a phone and a photo-diode. This hybrid system was presented in the first Visible Light Communication (VLC) workshop. Subsequently, over the past four years the field of VLC has grown significantly with several rolling-shutter based approaches for communication and localization, in both academia and start-ups. Our work was on of the earliest works in using VLC for localization.

% % \section{My research in other areas in CPS (short version)}
% % In addition to location, time is a fundamental property of CPS. I have worked on problems in time-synchronization \cite{buevich2013hardware, dongare2017pulsar, rtas-alps-platform}. Another CPS application I have worked on is electricity sensing in buildings and smart-grid scenarios.  Understanding appliance-level electricity consumption in a building is insightful, but it is impractical to install plug-through power meters for appliances with inaccessible wires and outlets.  We built a system that estimates the energy consumption of individual appliances using a wireless network of contactless electromagnetic field sensors deployed near each appliance, and a whole-house power meter \cite{rajagopal2013magnetic, rajagopal2013demo}.  Another area of my focus has been in the area of communications where we built one of the first prototypes of a system able to transmit data from LED lights to unmodified smart phones.  We exploited the rolling shutter camera sensors on these devices to detect high-frequency changes in light intensity \cite{rajagopal2014visual, rajagopal2014demonstration} and extended the system for low-power tags \cite{rajagopal2014hybrid}.  At a summer internship at Texas Instruments, I extended this work by exploring the design of hybrid Power Line and WiFi communication systems.


% \section{Future Work}
% My longer term vision is to build systems that 
% around sensing, perception and mobility. The complexity of the real-world signals and systems makes this space challenging and interesting. I am looking forward to collaborating with industry and researchers in diverse domains to solve problems in this space. 

% %CPS have high impact but it is hard to design systems that perform well in the real-world with limited resources. %I enjoy working at the interface of signals and systems to solve these problem in this space.
% % challenges. Working at the interface of the physical systems and embedded systems, and designing CPS to navigate the trade-off between performance and resources introduces hard research problems with high impact in the real-world. 
% %My future research direction includes localization and broader CPS challenges and applications. 
% %achieving the vision of infrastructure-free indoor localization, enabling next generation applications, solving 

% %Research plan includes extending localization to new applications, as well as applying my approaches to domains beyond localization.\\
% %\textit{Want to work on problems where physical world/ physical processes are tightly coupled with computing ; high performance with low resources --> high impact and hard problems.}\\
% \subsection{Indoor Localization}
% I want to realize the vision of an opportunistic infrastructure-free indoor localization ecosystem. My dissertation has taken steps towards this vision but there are still several problems to be solved. 
% On the estimation side, we can draw from the theory on mobile network localization. The challenges are in continuously mapping devices as well as localizing devices when the network is sparse and inertial measurements are poor. %I can draw upon ideas in location acquisition with low-beacon density and sensor fusion to address these challenges. 
% We also require novel discovery and medium access mechanisms for such an ecosystem since (1) devices appear, move and disappear, (2)  mixed-media ranging technologies such as BLE, WiFi, UWB, ultrasonic co-exist (3) beacons have to be continuously discovered and devices switch between acting as beacons and requesting for localization service. Most existing work is focused on accuracy and assume that the beacons are fixed, known and powered. %We require novel discovery and medium access mechanisms to solve these problems. 
% As steps towards these problems, I am working with NIST on firefighter localization using a networked mobile localization approach. Further challenges includes distributed sensor fusion at the edge. Another area of interest in network localization is using a network of devices for beam-forming in emerging communication technologies. %Location of the devices is key here.
% % Both in emergency and in general scenario.\\
% % NIST firefighter localization.\\
% % Mobile network localization\\
% % IMU accuracy\\
% % Crowd-sourcing 
% In summary, the challenges span sensing, estimation, medium access, communication and mapping. % and I would build on ideas from sensor-fusion and modeling to solve these challenges.
% %In all the CPS applications I have built, the scheduling and MAC problems have been different.
% %On the mapping side, we require crowd-sourced approaches to build maps of floor plans, beacons and other environmental signatures. The challenge is in building and sharing these maps 

% %For smart devices indoors to act as beacons when stationary 

% \subsection{Enabling next generation applications: Mixed Reality}
% Mixed reality is an exciting application that enables users to interact in new ways with the physical world. It has impact in domains ranging from entertainent, manufacturing, industrial, design, medical and training. State-of-art systems today 

% Mixed reality is an exciting CPS application with new challenges due to tight coupling between the digital and physical world. Mixed reality has applications is diverse domains ranging from manufacturing, entertainment, medical and training. Location is fundamental to mixed reality. For mixed reality to become a reality, we require accurate continuous estimation of the display device's pose and all physical and virtual entities that are part of the user experience to be represented in the same reference frame. I applied the location and orientation acquisition techniques for persistent mobile augmented reality that enabled multi-user applications and virtual content to persist in the same physical location over time. To interact with objects that do not have localizing capabilities we require new approaches. As part of the CONIX research center, I am working with other students on an LED-based visual marker for mixed reality applications. In future, I want to collaborate with researchers in computer vision to integrate visual information with other sensing signals for markerless mixed reality. 

% % An ideal user experience would require (1) accurate, continuous estimation of the display's pose with respect to the physical world, and (2) estimating the pose of other devices 


% % Mixed reality as an application takes CPS challenges to the next level. In mixed reality, the digital and physical worlds are tightly coupled. 
% % However there are other challenges. I applied our indoor localization work for mobile augmented reality. We are now integrating it with AR widgets. The next challenges are in markerless localization of things and devices that are not capable of ranging sensors. Some preliminary ideas are that,\\
% % Communication and localization

% % MArkerless AR 
% % Integration with vision
% % Physical search of devices
% % Time-sync and latency --

% % Applications are diverse - education, healthcare. Because human perception is in the loop, performance in terms of accuracy and latency is critical. Looking ahead, one direction I am interested in pursuing is in quantifying the performance of mixed reality systems in terms of the final application. For instance, when mixed reality is used for training and education, can we quantify the effect of the mixed reality experience on the user's training or improvement in learning? Some preliminary ideas are that 

% % A concrete use case is that..\\
% % Applications in 

% % I believe mixed reality pushes CPS challenges to the limit\\
% % Digital and physical worlds are tightly coupled in this application.\\
% % Because users are in the loop and humans perception is in the loop - performance (accuracy and latency) is critical \\
% % Challenges -  in estimation, timing and communication\\
% % Location is a key primitive to MR.\\
% % Mixed reality has applications in domains such as healthcare, education, manufacturing, entertainment. \\
% % I would like to collaborate with researchers in robotics to work on problems related to robot

% \subsection{Redesigning sensing systems with security as a performance metric}
% In addition to accuracy, timing and reliability, I want to design systems where security is performance metric that we account for. CPS are prone to attacks across various layers of the system stack - signals, sensors, network, and data processing. I am interested in the problems that arise due to attacks at the signal or physical layer. This problem space is challenging since the real-world is hard to model and the abstractions made by the data processing algorithms are likely not robust to attacks. For the system to be robust to attacks, we have to utilize additional resources. %main challenge I foresee is that the models used for estimation do not account for attacks. 
% %As a result there is a trade-off between making systems secure and utilizing lower amount of resources. %security as a performance metric trades-off with higher amount of resources . 
% As first steps in this direction, I want to explore problems in context of range-based localization. At the physical layer, there are two types of attack possible on the range/distance measurement - distance enlargement and distance reduction attack. The first question is - can we detect attacks on signals from a beacon? Some preliminary ideas are that we can use additional sources of information  such as the floor plan and check for consistency among signals from multiple beacons, similar to our approach for localizing in the presence of non-line-of-sight signals. This raises another challenge - how can we distinguish an attack from a real-world outlier? One possible direction is to use other sensing sources of information such as inertial sensors, as each sensing modality will have a different attack model that has to be satisfied for the attack to be undetectable. %I can build upon our multi-sensor approach and check for consistencies between other sources of information such as inertial signals. 
% Other questions I am interested in is - how would the beacon placement change, and how much more beacons do we require if we want security guarantees? Given robustness to certain attack models at the physical layer, how do the higher layers such as the MAC layer and device discovery process change? %Imagine a group of users creating AR content tied to physical locations that are not to be public but In a mixed-media ecosystem with several location-providing beacons and devices, and various applications we have to start thinking about whether access control and %The third question is, based on what attack modesl the physical layer is robust to, how would the MAC layer change, and what mechanisms can we introduce? 
% This summer, I briefly visited Prof. Sdrjan Capkun's Systems Security group at ETH Zurich to start exploring some of these problems in the area of secure localization. In the longer term, I am interested in a principled approach to sensing and estimation with security as a performance metric. %This space is challenging since the real-world is hard to model and the estimation algorithms use abstractions that are likely not robust to attacks. For the system to be robust to attacks, we have to utilize additional resources. % for attacks, we have to use additional resources.  %I have started exploring these questions with 
% %GPS is prone to attacks, but indoor spaces are private unless outdoors spaces. 
% %Accounting for security raises more questions, such as in the future should an infrastructure be authemticating a device, i scenarious where users hae access t different physcal resources, or to differtn digigtl reoures (AR conetnet). Another paradigm, is that users authenticate which infrastructure theytrust in a mixed ecosystem with several ranging technologies and devices owned by different users. 

% % Another problems space I am interested in is security in sensing systems, at the physical layer. For instance, localization systems are not designed to be robust to security attacks. Security is not part of the performance specifications while researchers are advancing this space. In range-based localization, some of the problems are - can a certain placement of beacons be more secure? While this problem has been studied for single room deployments, this is still an open problem for large -scale deployments. One of the main challenges I foresee is that, it is hard to distinguish between an attack, and an outlier measurement caused by the complexity of the physical world. For instance, how can we distinguish between a NLOS signal and a distance enlargement attack? To explore some of the problems in this space, I visited Prof. Srdjan Capkun's group at ETH Zurich to understand how the localization stack would change if we account for security. I see this problem space going beyond localization, more broadly to sensing systems. I believe this is an important problem space since attacks at the physical sensing layer cannot be detected at the higher layers of the application stack. Some preliminary ideas are that we can use multiple different sensors in an intelligent manner since the attack models are different for various sensing modalities.
% \subsection{Human in the loop CPS}
% A human in the loop of a CPS system poses new challenges with respect to prediction and estimation, but introduces new ways to improve performance using control and action by the human. In context of localization and mapping, the first step in this direction I want to explore is human-in-the-loop beacon mapping. Can we guide the user to walk towards a certain region or walk in a certain direction to improve the mapping accuracy with reduced time-to-estimate? A related problem is can the user move the mobile device in a certain manner to reduce the time taken to discover beacons as well as the time to acquire location and orientation with improved accuracy? The idea is that mobility increases sensory input. In the longer term, I am interested in exploring problems that arise when humans interact with CPS in applications such as mixed reality for training. Here the challenge is that the performance of the CPS has to meet the human perception requirements, and the CPS has to be robust to the unpredictability of humans. 
% % and we can leverage this to infer what mobility types  In the longer term, I am interested in
% % Problems: mapping. Exploring a space to increase sensory input based on mobility and motion. A concrete first problem is : SLAM - seen that we require diversity in walking pattern - how can we leverage this diversity? Mapping - automated with human input - from an estimation point-of-view, the challenge is in weighing uncertainity in the human input. \\
% % Systems that interact with humans - location is important\\
% % Another problem I am interested in is how we quantify performance of these systems with respect to 
% % The challenge in CPS design to achieve high performance with low resources is amplified when the human 
% % The eventual goal of CPS are to enable applications that 
% %\subsection{Broader CPS applications}
% %I would like to explore applications where the challenge in sensing and estimation is novel sensing systems for diverse challenging applications such as non-intrusive medical diagnosis,  sensing for agriculture,  industrial machine health diagnosis and civil infrastructure sensing, where I believe there are rich signals from which we can make meaningful inferences that guide action. The challenge in these applications is achieving performance with limited resources.\\

% %\subsection{Long-term vision}
% %My longer term vision is to understand and build systems around sensing, perception and mobility. The complexity of the real-world signals and systems makes this space challenging and interesting. I am looking forward to collaborating with industry and researchers in diverse domains to solve problems in this space. 
% %build cyber-phsystems that enhance
% %The real-world is full of signals rich in information and the challenge is in converting signals to information, with limited resources. 
% %Seamless transition between physical and cyber world. 
% %Perception and sensing systems that are scalable and high performance and work with the unpredictability and complexity of the physical world and humans. Collaborate with industry, standards, researchers in other disciplines. 



% %\subsection{Communication}


% %Prior work I used a sensing approach 
% %I worked on during my research at CMU. To solve this problem, 
% %Approaches for appliance-level load monitoring included 



% %While working with VLC, one of the questions that emerged was can we use power-line communication (PLC) as a backbone for VLC? 
 
% % One of the earliest problems I worked on at CMU was on solving the problem of dis-aggregating individual loads from a whole house energy meter. Prior work had solved this problem by adding intrusive plug-in meters for individual loads or performing device and installation-specific calibration on the whole house meter. 
% % %The question we asked is - Can we dis-aggregate loads in a non-intrusive manner without requiring
% % In contrast, we solved this problem using a novel sensing approach and a generalized model for home appliances. We designed a wireless sensor network consisting of contactless battery-operated electromagnetic field (EMF) sensors deployed near each appliance which detected appliance state transitions based on magnetic and electric field fluctuations. The model we assumed was that each appliance has two states on and off. We designed an estimation algorithm that used the EMF state transitions along with the whole-house power meter data to detect appliance state transitions \cite{rajagopal2013magnetic} and dis-aggregate individual load energy consumption, and also demonstrated this system \cite{rajagopal2013demo}. Working with energy metering and the electrical infrastructure of homes, a question that emerged was can we use the power lines as a communication channel indoors? Though there were standards for power line communication (PLC), the interesting question there was is it possible to design a communication scheme for PLC that could use the WiFi communication stack?  To explore this question, I interned at Texas Instruments Communications and Systems Lab and designed a hybrid communication scheme in simulation at the MAC and PHY layer. 

% % T
% % Prior, worked on energy metering, NILM, demo \cite{rajagopal2013magnetic, rajagopal2013demo}\\
% % Abstracted appliance state to on-off --> based on correlating mag fld to energy metering data\\
% % EMF for time-sync
% % TI - PLC-WiFi. Then looked at lights as an end-point for data tx
% % VLC - built one of the earliest works systems. Abstracted channel between light and camera. Hybrid system. Demoed. 
% % \cite{rajagopal2014visual} and extended the system for low-power tags \cite{rajagopal2014hybrid}. \\
% % \cite{rajagopal2014demonstration}\\


% % \section{Future research plans}
% % %location - a fundamental property of the physical world, and key to CPS that ißnte.  
% % CPS have immense potential, but also challenges.\\
% % Research plan includes extending localization to new applications, as well as applying my approaches to domains beyond localization.\\
% % \textit{Want to work on problems where physical world/ physical processes are tightly coupled with computing --> high impact and hard problems.}\\

% % \textbf{Mixed Reality}\\
% % I believe mixed reality pushes CPS challenges to the limit\\
% % Digital and physical worlds are tightly coupled in this application.\\
% % Because users are in the loop and humans perception is in the loop - performance (accuracy and latency) is critical \\
% % Challenges -  in estimation, timing and communication\\
% % Location is a key primitive to MR.\\

% % \textbf{Heterogeneous robotic systems}\\
% % We are at the point where robots are no longer confined to labs.\\
% % Aerial and ground robots.\\
% % Group of robots : example a drone + self driving car + mobile device coordinating and jointly estimating or doing a task.\\

% % \textbf{IoT}
% % Isn't IoT part of CPS? Not clear if I should keep this.

% %\textbf{Broader vision}\
% %Perception and sensing systems that are scalable and high performance and work with the unpredictability and complexity of the physical world and humans.



% % CPS end-end design is application specific. 
% % CPS - application-specific. I have worked on applications, on communication; 
% % VLC - imapct.\\
% % Indoor localization.\\





% %As a result, we either have either theory that is geneasystems that work well in lab environments and do not scale, or theory  %This makes it hard to design CPS in a principled manner. %A principled approach to sensing and estimation in CPS\\
% %My goal is to develop principled approaches that all

% %Physical things move - introducing complexity\\
% %dynamics of system over time\\
% %High fidelity model accurately represents the system\\
% %Physical + computing + networking





% %My approach is to bridge the gap between theory and practice of sensing and estimation in CPS by working at the intersection of estimation, signal processing, optimization and embedded sensing systems. 
% %Performance can be traded-off with cost by 
% %complexity and unpredictabiity of physical systems in the real-world makes it hard for these computing systems to be reliable at scale. 

% %Cyber-Physical Systems 

% %I am interested in a principled approach for sensing and estimation in cyber-physical systems (CPS) in the real-world. \\
% %I am interested in a principled approach for sensing and estimation in cyber-physical systems (CPS) in the real-world. 
% % Why CPS - goal of CPS
% % examples of CPS - swarm of robots, networked sys for indoor loc, smart grid, network of medical devices,
% %CPS enable us to estimate the state of the physical world, and 
% %% The physical world is complex. The ultimate goal is to accurately know the state of the physical world, and have the ability to 
% %Examples of what CPS can do potentially.
% %For instance, a network of drones coordinating on a task, devices estimating the state of a smart grid, personal and wearable devices together estimating health of a person, self-driving cars, etc.
% %What are CPS - should be clear that there is the physical world and based on the state of the physical world we want to take some actions.
% % CPS consist of sensors and actuators that interact with the physical systems, and computation components, often connected over a network.
% % % What does it even mean to have a good design of CPS?
% % The goal of a CPS is to monitor and effect a change in the state of physical processes. However, the complexity of physical processes pose several challenges to CPS design.
% % %Given a problem, how do we quantify what is a good CPS design to solve this problem? Solutions can vary in performance (accuracy, predictability, latency) and cost incurred (computational and infrastructure resources). 
% % %Challenges for CPS desigh emerge due to 
% % %What are the challenges in designing CPS?
% % %The real-world is complex and unpredictable, posing several challenges in the design of CPS. 
% % %The complexity of real physical systems pose several challenges to CPS design. 
% % First, it is hard to have accurate system models for physical systems that are part of CPS. Second, there is a trade-off between cost and performance in terms of the type, quality and quantity of sensors used.  Third, timing plays a role in both estimation and actuation, but measuring time across distributed physical systems is hard. Fourth, these systems often rely on communication and networking capabilities. 
% % My work spans the problems of timing and communication, but focuses on the problems related to estimation and sensing. 
% % \textit{A principled approach to CPS design is one that generalizes and also works in the real world.} 
% % A principled approach to CPS design is hard since solutions can vary in performance (accuracy, predictability, latency) and cost incurred (computational and infrastructure resources). 
% % %What it means to have a principled approach - this is critical
% % %Why we require a principled approach - this is critical
% % %Why is this hard?

% % My approach to solving these problems is to work at the intersection of theory and systems of CPS, with contributions to fundamental and applied research. I apply tools from estimation theory, statistical signal processing and optimization and build and deploy systems in the real-world. 


% % My dissertation is focused on location, a fundamental property of the physical world. %, key to indoor CPS.
% % \section{Research in indoor localization}
% % % why indoor localizatoin is important 
% % % why it is hard 
% % % our approach
% % % Three problems
% % % 	No systematic beacon placement - GDOP, CRLB. Toolchain, what we achieved. 
% % % 	Instant loc acquisition
% % % 	Ins orientation acq
% % % 	Mapping
% % % 	Applications
% % % 		FF
% % % 		mobile AR
% % Knowing where people and things are inside buildings will impact several domains and open up new applications. Some examples are location-based physical search for things, spatially-aware communication, drones navigation indoors, and interactive mixed reality. Though several techniques exist, indoor localization at scale is not yet a reality. The challenges draw from the traditional challenges of CPS - in sensing and estimation, time-synchronization and communication. My work addresses these challenges, towards the vision of an infrastructure-free opportunistic indoor localization ecosystem that can accurately and instantly locate things, devices and people.\\ %Towards this vision, my work addresses four challenges faced by localization, which arise due to  

% %\textbf{Research}
% % The first challenge for localization is that it has to support heterogeneous devices with varied sensing capabilities. My approach to this is to
% % %I believe that to enable indoor localization to become a reality, 
% %  embrace the emerging ranging and localization technologies that are finding their way into newer standards and mobile devices, and build an ecosystem that enables these technologies to scale up and be integrated with heterogeneous sensors. \textit{talk about range-based localization systems and envisioned ecosystem. }.\\%solve the problems that these systems face which scaling up. My world adopts a sensor fusion approach 
% % %My approach: range-based localization\\

% % The second challenge is that there is no systematic understanding of how and where to place range-based beacons. My approach to this is to abstract the floor plan and beacon ranges to models where we can apply concepts from estimation theory. Currently, beacon placement is done empirically by domain-experts, and indoor spaces are over-provisioned with beacons. Existing approaches require three or more beacons to determine a unique position solution. I show that with prior knowledge of the map and a model of beacon coverage, it is possible to uniquely localize with only two beacons. I introduce a metric to quantify the quality of a beacon placement and design an algorithm for systematically placing beacons in a floor plan. This is based on the Cramer Rao Lower bound on the location estimate, under the assumption that the ranging noise is additive white noise Gaussian. When applied to a set of real floor plans, this placement algorithm is able to reduce the number of beacons by 33\% on an average as compared to standard approaches. \\

% % The third challenge is that in reality, signals from line-of-sight beacons get blocked, we also receive incorrect non-line-of-sight (NLOS) signals. To maintain accuracy despite these, either beacons are over-provisioned (trading-off cost) or other sensor measurements are used over time, or the user is asked to walk around (trading-off time-to-estimate). To solve this problem, I design a new floor-plan aware location estimation technique that can instantly acquire location  
% % %Our second contribution is a localization algorithm that is able to instantly acquire location 
% % in the presence of low-beacon density and incorrect non-line-of-sight (NLOS) signals. 
% % %To get accurate location in the presence of non-line-of-signals, existing approaches either deploy beacons with high-density (increasing cost) or use inertial-tracking to converge on an estimate over time (increasing time-to-first-fix). 
% % This solving approach uses the floor plan information and can disambiguate multiple feasible locations taking into account a mix of LOS and NLOS hypotheses to accurately localize instantly with significantly fewer beacons. When evaluated in multiple real deployments, our approach was able to improve the 80\% localization accuracy from 4-8m to 1m in low-beacon density and NLOS conditions.

% % The fourth challenge is that for many applications, we require to know the orientation of the device in addition to location. However, 
% % %Our third contribution is to estimate instant orientation, in addition to location. 
% % typical approaches for orientation acquisition use the mobility of the device (trading-off time-to-estimate). I propose an approach where we can leverage the magnetic field along with the localization system to 
% % %We use the location estimated from a beacon infrastructure along with a map of magnetic field direction to 
% % instantly estimate the device’s orientation immediately without requiring the user to walk around. Our system provides 90\% localization accuracy of 24cm with LOS beacons and 90\% orientation acquisition accuracy of 16° from magnetic field sensing.\\

% % The final challenge - is mapping. We also present a pedestrian-aided automatic mapping approach for mapping the beacons and magnetic field rapidly upon setup... \\

% % In summary, there are several ways of solving the localization problem. However, the real challenge is in solving it in a manner that maintains performance (high accuracy, low time-to-estimate) in a manner that is also cost efficient (low infrastructure, mapping and setup effort). My work addresses these challenges in a principled manner by creating new models and estimation techniques. \\

% % \textbf{Demonstration of approach, and applications}\\
% % Here talk about - above is contribution to fundamental research.\\
% % But we have also demonstrated and deployed\\
% % Localization competitions\\
% % %Demo\\
% % ALPS - startup\\
% % Mobile AR\\
% % NIST firefighter localization with smart EXIT signs with TI


% %Being able to locate people and things inside a building accurately and instantly in a cost-effective  manner  will  revolutionize  the  way  we  interact  with  our  indoor  surroundings  and open up new application domains ranging from location-based authentication, drone navigation indoors to future intefaces using mixed reality. 

% %These applications range from indoor navigation, search and rescue, location-based authentication, smart buildings to future interfaces using mixed reality. However, indoor localization at scale is not yet a reality due to two reasons. First, the technical barriers in terms of what sensors are available on commodity devices, and second, indoor localization faces the  typical CPS challenges in scaling up from labs to real-world. 
% %Indoor localization at scale is not yet a reality due to technical barriers in  terms  of  what  sensors  are  available  on  commodity  devices  today,  and  gaps  in  scaling these systems from labs to realistic building environments.  
% %
% %I believe that to enable indoor localization to become a reality, we should embrace the emerging ranging and localization technologies, and solve the problems that these systems face which scaling up. My work takes a principled approach to solving the problems faced by emerging ranging and localization technologies while scaling up, with regard to sensor placement, mapping and noisy sensormeasurements.  More generally, I apply tools from estimation theory and statistical signalprocessing to real-world embedded sensing systems.

% %\section{Research in other areas of CPS}
% %In addition to localization, I have worked on problems in the area of time-synchronization, energy monitoring and communication in context of CPS. 




\newpage
\small
\bibliographystyle{abbrv}

\bibliography{references}  % sigproc.bib is the name of the Bibliography in this case

\end{document}
